\section{Library modules}
\label{sec:modules}

\subsection{Import}
\label{sec:modules:import}

The import module implements the SCOOP \lstinline!import! feature, which should be built-in but isn't implemented at the moment.
It is one of the most important modules of the library.
It consists of all classes in the directory \dir{library/import}.

The basic concepts on how to use the module is described in Section \ref{sec:concepts:import}.
This section only describes the descendants of \lstinline!CP_IMPORTER!, which provide predefined import functions for some types and support for writing an import feature manually.

The deferred class \lstinline!CP_IMPORTER [G]! defines the basic interface for a manually defined import feature.
To define an import feature for an arbitrary type, e.g. \lstinline!STRING!, one has to inherit from \lstinline!CP_IMPORTER [STRING]! and provide an implementation for the deferred \lstinline!import! feature.

% The main class is the deferred \lstinline!CP_IMPORT_STRATEGY [G]!, which has the simple interface:
% \lstinputlisting [firstline=7] {../../library/import/cp_import_strategy.e}
% By implementing \lstinline!import!, descendants can decide if an object of type \lstinline!G! shall be imported and if yes, how it's done.
% 
% The class \lstinline!CP_NO_IMPORTER[G]! is the default class to disable import and just perform a reference copy.
% Every other importer can inherit from \lstinline!CP_IMPORTER!, which narrows the return type of \lstinline!import! to a non-separate \lstinline!G!.

Because writing an extra importer for every importable object may be tedious, there's a support class \lstinline!CP_IMPORTABLE!:

% \lstinputlisting [firstline=7] {../../library/import/cp_importable.e}
\begin{lstlisting}
deferred class
	CP_IMPORTABLE

feature {CP_DYNAMIC_TYPE_IMPORTER} -- Initialization

	make_from_separate (other: separate like Current)
			-- Initialize `Current' with 
			-- the same values as `other'.
		deferred
		end

end
\end{lstlisting}

That way an import function can be written right inside the class that needs to be imported.

There are two classes which can be used for \lstinline!CP_IMPORTABLE! objects: \lstinline!CP_DYNAMIC_TYPE_IMPORTER! and \lstinline!CP_STATIC_TYPE_IMPORTER!.

The latter uses bounded genericity to directly create an object of type \lstinline!G!.
This has the drawback however that the type is statically \lstinline!G!, even if the argument to \lstinline!import! was of a subtype of \lstinline!G!.

The \lstinline!CP_DYNAMIC_TYPE_IMPORTER! tries to avoid this problem by using reflection.
This introduces a new problem with respect to void safety however, as the new object will not be initialized.
Therefore it is strongly advised to declare \lstinline!make_from_separate! as a creation procedure for every descendant of \lstinline!CP_IMPORTABLE!.

Another problem of the \lstinline!CP_DYNAMIC_TYPE_IMPORTER! are the invariants of an object.
There's a short time interval between the creation of an object (using reflection) and the call to \lstinline!{CP_IMPORTABLE}.make_from_separate! where the invariants are broken.
Due to this, it is not possible to have invariants in a class that will be imported using the dynamic type importer.

In the future, there will hopefully exist an import routine natively supported by the SCOOP runtime.
In that case \lstinline!CP_IMPORTER! can be made effective and use the native import, and all its descendants will become obsolete.


% Other components of the library often use the import module via bounded genericity.
% The class \lstinline!CP_QUEUE! for example has the ability to import objects, and it's class header looks like this:
% \begin{lstlisting}
% class CP_QUEUE
%   [G, IMPORTER -> CP_IMPORT_STRATEGY [G] create default_create end]
% feature
%   ...
% end
% \end{lstlisting}
% That way a user can decide on the precise semantics of the import strategy by just declaring the right type.

\subsection{Queue}

The queue module is a simple queue implementation in class \lstinline!CP_QUEUE!.
It is mostly used to easily implement the producer / consumer pattern in a concurrent context.


The pattern itself is all about data migration as described in Section \ref{sec:object-migration}.
Therefore the queue module makes heavy use of the import mechanism.
This means that, along with a generic argument for the data type, it is also necessary to provide a \lstinline!CP_IMPORT_STRATEGY!.
The import strategy then basically ``teaches'' the queue how to import a given object.

Internally, \lstinline!CP_QUEUE! uses an \lstinline!ARRAYED_LIST! to store its elements.

As the \lstinline!CP_QUEUE! is intended to be used as a separate object, the module provides support classes that implement the Separate Proxy pattern.

% It uses the separate proxy pattern, which means that it consists of three classes:
% 
% \begin{itemize}
%  \item \lstinline!CP_QUEUE!
%  \item \lstinline!CP_QUEUE_UTILS!
%  \item \lstinline!CP_QUEUE_PROXY!
% \end{itemize}
% 
% The first one provides the actual queue, but internally it just relies on \lstinline!ARRAYED_QUEUE!.
% The class \lstinline!CP_QUEUE_PROXY! can be used to access such a shared, separate queue without having to deal with separate references.
% 
% The interesting thing about this queue implementation is that it makes use of the import module.
% Along with the generic argument \lstinline!G! you can also provide an \lstinline!CP_IMPORT_STRATEGY [G]!.
% The import then happens automatically in both the queue and its proxy.

% \subsubsection{Producer / Consumer}
% 
% 
% The producer / consumer is a very popular pattern in concurrent programming, and it is a building block for other patterns like pipeline as well.
% The basic idea is to have a shared, concurrent buffer.
% Producer threads put new items into the buffer, whereas consumer threads remove items from this buffer.
% 
% \todo{BON-style diagram and ``migration graphics''}
% 
% In threaded systems, this buffer is usually accessed by several threads at the same time.
% Careful synchronization has to be enforced to ensure that the buffer remains in a consistent state.
% The data items on the other hand ``migrate'' from a producer to the buffer, and then to exactly one consumer.
% They therefore don't need to be thread-safe as long as the producer promises never to touch the item again.
% 
% In SCOOP things look a bit different however.
% Due to the exclusive access guarantee it is not necessary to establish a synchronization policy.
% The downside however is a loss of potential concurrency when a producer and a consumer accesses the buffer simultaneously, but this is a minor problem.
% 
% The main problem in SCOOP are the data items, especially if they are not of an expanded type.
% If the object is created on the producer processor, then the consumer needs to control the producer in order to get access to the object.
% This is clearly a situation that we want to avoid, because it couples the producer and consumer in a vicious hidden way, and the whole point of the producer / consumer pattern is to decouple the two.
% 
% A nice solution would be if it's somehow possible to migrate data items, like it's done in threaded languages.
% However, this is not possible with the current semantics of SCOOP, because an object always stays on the processor it was created on.
% 
% One approach to solve this problem is to create a new processor for every data item.
% This actually works, but it can be very slow, especially for a lot of small data items.
% There are two reasons for this:
% First, every SCOOP processor is mapped to an operating system thread, therefore creating a new processor involves creating a new thread which is an expensive operation.
% The second reason is the overhead of separate calls itself.
% This has to be paid every time the consumer wants to access the separate object.
% 
% Another problem of this approach is related to ease of programming.
% Dealing with a separate object can be very annoying, because you need to write small wrapper functions for every little feature call.
% 
% \begin{lstlisting}
% class
%   CONSUMER
% 
% feature -- Basic operations
%   
%   retrieve
%       -- Retrieve a string and print its length.
%     local
%       l_string: separate STRING
%     do
%       l_string := buffer_consume (a_queue)
%       print (string_count (l_string))
%     end
%     
% feature {NONE} -- Implementation
%   
%   buffer: separate BUFFER [STRING]
% 
%   buffer_consume (a_buffer: like buffer): separate STRING
%       -- An annoying small wrapper function for a buffer.
%     do
%       Result := a_buffer.item
%       a_buffer.remove
%     end
%     
%   string_count (a_string: separate STRING): INTEGER
%       -- An annoying small wrapper function for a string.
%     do
%       Result := a_string.count
%     end
% end
% \end{lstlisting}
% 
% 
% Due to these problems we decided to go for a different strategy: cloning objects.
% Using the import module it is possible to ``teach'' the shared buffer how to clone any user-defined object by just providing a generic argument.
% A first library for the producer / consumer pattern thus consisted of the class \lstinline!CP_QUEUE! and \lstinline!CP_IMPORT_STRATEGY!, along with some predefined importers.
% 
% The import trick solves the main problem of the producer / consumer, namely migrating objects from producer to consumer efficiently.
% However, producers and consumers still have to deal with a nasty separate reference (the shared buffer), and there's also the problem that a user of the library might forget to import objects on the consumer side.
% 
% To overcome this problem we implemented a non-separate proxy class which automatically deals with the separate reference and imports.
% This idea proved to be so successful that eventually it was turned into its own pattern: the separate proxy.
% 
% \todo {Bon-style graphics of CP\_QUEUE and related items.}


\subsection{Process}

The process module provides a set of classes that all implement some sort of skeleton for a main loop.

The class \lstinline!CP_PROCESS! defines the interface.
It is a descendant of the class \lstinline!CP_STARTABLE!, such that clients have a simple way to start a separate process using \lstinline!CP_STARTABLE_UTILS!.

The feature \lstinline!start! is used to start the main loop.
As the process module defines the skeleton for a main loop, users are just required to implement \lstinline!step!, which should contain the body of the loop.
The loop can be exited by setting the attribute \lstinline!is_stopped! to \lstinline!True!.

\lstinline!CP_PROCESS! also introduces the two methods \lstinline!setup! and \lstinline!cleanup!.
They are called in the beginning or at the end of the main loop, and must be explicitly redefined by descendants if needed.

There are two different implementations for the main loop itself.
The first, used by \lstinline!CP_CONTINUOUS_PROCESS!, is pretty staightforward:
\begin{lstlisting}
from setup
until is_stopped
loop
  step
end
\end{lstlisting}
The advantage of this approach is its simplicity.
However, other processors never get a chance to access data which is handled by the processor of the \lstinline!CP_CONTINUOUS_PROCESS!, unless the main loop is exited completely.
This class is a simple implementation of the \lstinline!Active Object! pattern \patternref{AO}.

The second implementation in \lstinline!CP_INTERMITTENT_PROCESS! is more interesting.
The basic idea is to perform only one iteration, and then tell another processor to inoke the loop body again in \lstinline!Current!.
This ping-pong approach ensures that after every iteration other processors may get a chance to access and modify data in \lstinline!CP_INTERMITTENT_PROCESS!.
In practice this is especially useful to stop a \lstinline!CP_INTERMITTENT_PROCESS! from the outside.

\lstinline!CP_INTERMITTENT_PROCESS! implements the Asynchronous Self-Call pattern \patternref{ASC}.
The callback service is provided by the class \lstinline!CP_PACEMAKER!, and every \lstinline!CP_INTERMITTENT_PROCESS! automatically creates an associated pacemaker.

The \lstinline!CP_PERIODIC_PROCESS! allows to add small delays between executions. 
It is a refinement of the \lstinline!CP_INTERMITTENT_PROCESS! and an implementation of the Timer: Periodic pattern \patternref{TP}.
The class also introduces the simple command \lstinline!stop!, which can be used to stop the process from the outside.


\subsection{Worker pool}
\label{sec:worker_pool} 

% The worker pool module provides support classes to build a worker pool.
% It makes use of the queue module to store the work items.
% 
% The module consists of three classes:
% 
% \begin{itemize}
%  \item \lstinline!CP_WORKER!
%  \item \lstinline!CP_WORKER_POOL!
%  \item \lstinline!CP_WORKER_FACTORY!
% \end{itemize}
% 
% The last one is just an factory class to create the user-defined \lstinline!CP_WORKER! objects.
% 
% The deferred class \lstinline!CP_WORKER! has a predefined main loop, where the object first checks if it needs to terminate, then grabs a new work item, and processes it.
% The processing step is deferred and needs to be implemented by the user.
% 
% The \lstinline!CP_WORKER_POOL! is the central management instance.
% Its primary task is to accept new work items from clients, but it can also be used to adjust the number of workers in the pool and to terminate all workers.
% The \lstinline!CP_WORKER_POOL! also implements the separate proxy pattern, which means that clients should access it through \lstinline!CP_WORKER_POOL_PROXY!.
% 
% \subsection{Worker pool}

A worker pool is a set of threads that are ready to execute tasks.
The intention of the worker pool is to make use of parallelism but avoid the overhead of thread creation, which can be quite expensive especially for small tasks.

The main component of the worker pool is a shared buffer, where clients can insert tasks to be executed.
A worker thread will then repeatedly retrieve a task from the buffer and execute it.
The worker pool module makes use of the queue module, which provides the shared buffer.
  %producer / consumer pattern, with the library client as a producer and the worker threads as consumers.

%An important part of the worker pool is also the ability to increase or decrease the amount of worker threads, or to completely stop all worker threads such that the application can terminate.

The representation of a task to be executed varies between different languages.
In Java for instance a Runnable \todo{ref?} object is used, whereas in C\# the task is represented as a delegate \todo{ref?}.

In SCOOP there's the problem of object migration, as described in Section \ref{sec:object-migration}.
If the task object is created on its own processor, as in the Data Processor approach, you cancel out the performance gain you tried to achieve with the worker pool.
With the Lock Passing approach, a task object will be executed on the processor that created the object, which kind of makes the worker pool useless (not to mention the risks of processor starvation if applied wrong).
This only leaves the Import mechanism as a sensible solution.

In the library we support two flavors of a worker pool.
The first and more basic one is to have a deferred class \lstinline!CP_WORKER! where clients can directly implement an operation.
The object submitted to the worker pool then corresponds to the arguments of the operation.

The second solution uses a special task class to encapsulate an operation.
It is described in Section \ref{sec:arbitrary-operations}.

% However, there are two solutions to this problem: You can either use the import mechanism, or make the worker class deferred and let clients implement the task directly.
% In the library we support both approaches, although the latter can be used to implement the import solution.
% Section~\ref{sec:arbitrary-operations} shows how to do this.

The basic worker pool module has three main classes:
\begin{itemize}
 \item \lstinline!CP_WORKER_POOL!
 \item \lstinline!CP_WORKER!
 \item \lstinline!CP_WORKER_FACTORY!
\end{itemize}

The \lstinline!CP_WORKER_POOL! provides the shared buffer and some additional functionality to adjust the pool size.
The type of the task object alongside its import strategy can be specified with a generic argument.
\lstinline!CP_WORKER_POOL! inherits from \lstinline!CP_QUEUE! and therefore uses the same import mechanisms.

The deferred class \lstinline!CP_WORKER! corresponds to the worker thread in other languages.
Users need to implement the feature \lstinline!do_run!, which takes a task object and executes it.
The exact type of the task object depends on the generic arguments of \lstinline!CP_WORKER!, which must be the same as in \lstinline!CP_WORKER_POOL!.
The non-deferred part in \lstinline!CP_WORKER! is the main loop itself, which fetches a new task, calls \lstinline!do_run!, and checks if the worker needs to terminate.

The last class, \lstinline!CP_WORKER_FACTORY!, just provides a deferred factory function for a new worker.
The factory class is necessary because the exact type of \lstinline!CP_WORKER! is not known to the library.
With a user-defined factory, the \lstinline!CP_WORKER_POOL! can create new workers on demand.




% \subsubsection{Terminating workers}

An important functionality of a worker pool is to adjust the number of workers.
Increasing the worker count is not a problem, as you can just create new \lstinline!CP_WORKER! instances using the factory.
To decrease the amount of workers, the module makes use of the processor termination technique described in Section \ref{sec:processor-termination}.


% However, decreasing the amount of workers is not that easy.
% 
% Java provides two builtin mechanisms to shut down a thread.
% You can either force it to stop, which immediately throws an exception in the thread \todo{ref}, or you can use the more collaborative interrupt mechanism \todo{ref}.
% The idea is that the thread will regularly check its interrupted flag and terminate on its own if requested.
% 
% The latter is also possible to do in SCOOP, except that there's no builtin interrupt flag.
% Instead a query \lstinline!is_stop_requested! in \lstinline!CP_WORKER_POOL! can be used.
% The main problem however are wait conditions.
% 
% In Java, blocking calls like \lstinline!wait()! and \lstinline!sleep()! may throw an \lstinline!InterruptedException! \todo{ref}.
% This avoids the problem that a thread may wait forever instead of shutting down, because all signaller threads have already terminated.
% Unfortunately, there's no such mechanism in SCOOP.
% It is possible however to work around this limitation by refining the wait condition:
% \begin{lstlisting}
% 
% class
%   CP_WORKER
%   
%   -- ...
%   
% feature -- Implementation
% 
%   fetch (pool: separate CP_WORKER_POOL)
%     require
%       not pool.is_empty or pool.is_stop_requested
%     do
%       if is_stop_requested then
% 	-- Stop the currrent worker.
%       else
% 	-- Grab the next item.
%       end
%     end
% 
% end
% \end{lstlisting}
% The additional \lstinline!if! statement is not very nice, but luckily it can be encapsulated completely in \lstinline!CP_WORKER!.
% 
% This code snippet is useful to break free of any wait condition if the requirements have changed.


The Separate Proxy pattern is applied to \lstinline!CP_WORKER_POOL! to simplify the use of a separate worker pool object.

The basic worker pool module allows for a very flexible use. 
It is for example possible to use it just as an advanced producer / consumer module where consumers are automatically created and destroyed.
The next section introduces a more advanced implementation of the worker pool which builds on the basic module.



\subsubsection{Arbitrary operations}
\label{sec:arbitrary-operations}

So far the task of a worker is defined in a user-defined \lstinline!CP_WORKER! class, and the object submitted to the worker pool mostly contains data.
The worker pool implementations in Java and C\# only accept Runnable (or delegate) objects.
This enables arbitrary operations that can be executed by the worker threads.

The SCOOP version of the worker pool can be enhanced to act like the Java / C\# counterparts.
To do that we need a class that represents an operation, and which can be moved across processor boundaries.

The agent classes in Eiffel (i.e. ROUTINE and descendants) may be used to represent operations, but they can't be easily imported.
That's why we added a new, deferred class \lstinline!CP_TASK!.
Users of the library can inherit from it and implement the feature \lstinline!run!.
\todo {Tell about agent integration?}

Using this interface it is possible to have a predefined \lstinline!CP_TASK_WORKER! that just runs \lstinline!CP_TASK! objects.
The associated \lstinline!CP_TASK_WORKER_POOL! implements the factory function and refines the raw \lstinline!CP_WORKER_POOL!.

The combination of these two classes is very close to the Java worker pool implementation.
The only difference is that a \lstinline!CP_TASK! object needs to be imported, whereas a Java Runnable object doesn't.


\todo{Maybe merge subsections Arbitrary Operations and Promise into a new section that describes the ideas behind CP\_TASK?}

\subsection{Futures}
\label{sec:futures}

The future pattern is used to perform a computation asynchronously.
Instead of computing a value directly, the computation gets wrapped into an object and the user only receives a handle to retrieve the value when it's ready.
This handle is often called Future, Promise or Delay.
In this section we'll use the term Future for the whole pattern, and Promise only refers to the handle.

The main advantage of the future pattern is that it allows to make use of parallelism in an easy way.
A user just has to spot computations which may run asynchronously, and the future pattern takes care of thread management, synchronization and result propagation.

The future pattern consists of four building blocks:
\begin{itemize}
 \item The Promise object,
 \item the computation,
 \item the execution service,
 \item and a ``frontent'' object which takes a computation, submits it to the executor, and returns a Promise object.
\end{itemize}

The representation of the computation is a Callable object in Java and a delegate in C\#.
Our library uses the interface \lstinline!CP_COMPUTATION! with the deferred feature \lstinline!computed!.
It is a descendant of \lstinline!CP_TASK! introduced in Section \ref{sec:arbitrary-operations}.

The Promise object is defined by \lstinline!CP_PROMISE! and its descendants.
The detailed implementation is described in Section \ref{sec:promise}.

The execution service part of the Future pattern can vary.
In most cases it is a worker pool which executes the computation objects and updates the Promise with the correct result.
However, it is also possible to implement it as a single thread, or even to executing them synchronously in the current thread.

To take this variation into account, we added the interface \lstinline!CP_EXECUTOR!.
The \lstinline!CP_TASK_WORKER_POOL! introduced in Section \ref{sec:worker_pool} implements this interface and thus can be used as an executor service for the Future pattern.
We also applied the Separate Proxy pattern on \lstinline!CP_EXECUTOR!, as it is mostly accessed through a separate reference.

\todo {Maybe highlight that EXECUTOR is not just for the future pattern, but a general implementation of the Executor pattern.}

The ``frontend'' part is implemented in the \lstinline!CP_EXECUTOR_PROXY!.
This is an example where the responsability of a proxy object has been expanded:
Instead of just forwarding the \lstinline!CP_COMPUTATION! to the execution service, it also creates the Promise object and returns it to the user.

The implementation of the future pattern in SCOOP hits two challenges:
\begin{itemize}
 \item Object Migration (see Section \ref{sec:object-migration}: Operations can't be easily moved from the client to an execution service.
 The same is also true for the result of a computation in the reverse direction.
 \item Processor Communication (see Section \ref{sec:processor-communication}: The promise object should neither be placed on the client processor nor on the executor service.
% The reason in both cases is that one processor may execute a main loop, which means the other processor never gets access to the promise object.
\end{itemize}

The solution to the first problem is, once again, the import concept (Section \ref{sec:concepts:import}.
% This means that both the Executor service and the Promise object have a generic argument to define the \lstinline!CP_IMPORT_STRATEGY!.
% The executor service always uses \lstinline!CP_DYNAMIC_TYPE_IMPORTER!, because \lstinline!CP_COMPUTATION! inherits from \lstinline!CP_IMPORTABLE!.
% The import strategy of the Promise object however is user-defined.
The second problem is more interesting however.
As we've seen in Section \ref{sec:processor-communication}, the Promise object needs to be placed on a third processor.

However, if we start a new processor for every computation, we introduce a huge overhead.

A better tradeoff would be to introduce one global processor, which takes care of all promise objects.
This may introduce contention if multiple futures are submitted, but we think that this is acceptable.

However, this approach brings another problem.
A promise object has two generic arguments for the return type and the import strategy.
As these arguments are not known in advance, and because SCOOP processor tags \cite[p. 90]{Nienaltowski07} are not implemented yet, it is not possible to create a promise object on this dedicated processor.

The solution is - surprisingly - the import module.
We can create a promise object with the correct types on the client processor, and then ask the global processor to import it.
This way the promise object finally ends up on the correct processor.

% In the library, the Promise object is provided by the class \lstinline!CP_PROMISE! and its descendants.
% The computation is represented with \lstinline!CP_COMPUTATION!, or \lstinline!CP_TASK! for operations that don't return a result.
% The execution service is the deferred class \lstinline!CP_EXECUTOR! and \lstinline!CP_TASK_WORKER_POOL! is the main implementation.
% 
% The separate proxy pattern is applied on \lstinline!CP_EXECUTOR! and \lstinline!CP_PROMISE!.
% Besides acting as a processor-local proxy to a separate \lstinline!CP_EXECUTOR!, 
% the classes \lstinline!CP_EXECUTOR_PROXY! and \lstinline!CP_FUTURE_EXECUTOR_PROXY! are also responsible to create Promise objects on the global processor.

\subsubsection{Promise}
\label {sec:promise}

The promise module contains a set of classes which can be used to monitor the state of an asynchronous operation.

The main class is \lstinline!CP_PROMISE!, which defines queries like \lstinline!is_terminated! or \lstinline!is_exceptional!.
It also defines the interface to cancel a task or to get the progress percentage (e.g. for a download task), but these queries need to be supported by the task itself.

The Separate Proxy mechanism is available for promise objects, because they are usually declared separate to the client.
In this case the pattern is implemented with four classes, i.e.
\begin{itemize}
 \item \lstinline!CP_PROMISE! defines a common interface,
 \item \lstinline!CP_SHARED_PROMISE! defines the actual separate object,
 \item \lstinline!CP_PROMISE_UTILS! introduces helper functions to access a \lstinline!separate! \lstinline!CP_PROMISE! and
 \item \lstinline!CP_PROMISE_PROXY! is the proxy object.
\end{itemize}

There's an important descendant, the \lstinline!CP_RESULT_PROMISE!, which is used for asynchronous operations that return a result.
It also has a set of associated classes that implement the Separate Proxy pattern.

The \lstinline!CP_RESULT_PROMISE! contains a query \lstinline!item! to retrieve the result as soon as it's available.
A distinguishing feature of this query is that it blocks if the result is not yet available.
The return type of \lstinline!item! depends on a generic argument.
To migrate the result back to the client, this class makes use of the import module - i.e. the \lstinline!CP_SHARED_RESULT_PROMISE! and \lstinline!CP_RESULT_PROMISE_PROXY! both have an additional generic argument which defines the import strategy.

% The \lstinline!CP_RESULT_PROMISE! is used for the future pattern.

% \subsubsection{Executor}
% 
% The executor module can be used to execute varying operations.
% The main class is \lstinline!CP_EXECUTOR!, which provides facilities to execute a \lstinline!CP_TASK! objects.
% 
% \lstinline!CP_TASK! itself represents a user-defined operation.
% It can be imported across processor boundaries and provides exception handling.
% To define a new task a client needs to inherit from \lstinline!CP_DEFAULT_TASK! and implement the feature \lstinline!run! and \lstinline!make_from_separate!.
% 
% A special kind of task is \lstinline!CP_COMPUTATION!, which can also return a value.
% This is needed to implement the future pattern.
% 
% The \lstinline!CP_EXECUTOR! makes use of the separate proxy pattern.
% However, the proxy also enhances the raw \lstinline!CP_EXECUTOR! interface with the option to attach a \lstinline!CP_PROMISE! object to a task.
% This can be used to query the status of a task, await termination, or get the computed result back in case of a \lstinline!CP_COMPUTATION!
% All \lstinline!CP_PROMISE! objects are created on a dedicated processor to avoid unnecessary thread creation.
% 
% An important implementation of the \lstinline!CP_EXECUTOR! is the \lstinline!CP_TASK_WORKER_POOL!.
% As the name suggests, this is a worker pool where each worker repeatedly executes \lstinline!CP_TASK! objects.
% 
% \todo {More executor implementations?}
