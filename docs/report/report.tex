\documentclass[a4paper,10pt]{report}
\usepackage[utf8]{inputenc}

\usepackage{pattern}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{todo}

\newcommand{\dir} [1] [] {#1} 

% Title Page
\title{Concurrency Patterns in SCOOP}
\author{Roman Schmocker}


\begin{document}
\maketitle

\begin{abstract}

\end{abstract}

\tableofcontents

\section{Introduction}

\section {The SCOOP model}
% Introduction, differences to Java etc... (short)

\section {Pattern overview}
% Overview of all patterns, maybe tabular

\pattern [ name={Single Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to exactly one shared object or resource.}
  ,applicability={Shared memory systems}
  ,status={Implemented language mechanism}
  ,example={A counter variable that shold only be incremented by one thread at a time to avoid lost updates.}
  ,knownapps={The Java ``synchronized'' block implements single exclusive access, as well as C\# ``lock''.}
  ,relation={Usually implemented with some kind of locking mechanism.}
  ]

\pattern [ name={Multiple Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to several shared objects or resources.}
  ,applicability={Shared memory systems}
  ,status={Implemented language mechanism}
  ,example={A money transfer between two bank accounts.}
  ,knownapps={Databases can provide exclusive access over all data previously used in the same transaction.}
  ,relation={It is possible to use nested single exclusive access to provide multiple exclusive access, but special care has to be taken with deadlocks.}
  ]

\pattern [ name={Import}
  ,category={Language limitation}
  ,intent={Copy an object structure from a separate processor to the local processor.}
  ,applicability={SCOOP only. Requires some client support.}
  ,status={Implemented library component; future language mechanism}
  ,example={Copy the HTTP request from the network socket listener to a request handler, such that the listener can continue.}
  ,knownapps={The library makes heavy use of this pattern.}
%  ,relation={}
]

\pattern [ name={Self Asynch}
  ,category={Program structuring}
  ,intent={Allow other processors to access and modify data on the current processor despite running in a main loop.}
  ,applicability={SCOOP only}
  ,status={Implemented library component}
  ,example={A network socket listener that may be stopped by another process.}
  ,knownapps={The timer pattern and the echo server use self asynch.}
  ,relation={Similar to the Active Object pattern, except that other processors may access data after each iteration.}
]

\pattern [ name={Separate Proxy}
  ,category={Program structuring}
  ,intent={Provide easy access to a separate object.}
  ,applicability={SCOOP only}
  ,status={Guideline}
  ,example={A shared buffer in a producer / consumer setting, where every producer and consumer creates a proxy on its own processor to avoid dealing with separate references.}
  ,knownapps={The CP\_BROKER and CP\_QUEUE classes have predefined proxies.\todo {inline listings}}
  ,relation={The separate proxy is a special version of the more general GoF \todo{ref} proxy pattern.}
]

\pattern [ name={Future}
  ,category={Program structuring, Performance}
  ,intent={Run a task asynchronously, and fetch the result later.}
  ,applicability={Asynchronous operations}
  ,status={Implemented library component, implemented language mechanism.}
  ,example={Download a file in the background.}
  ,knownapps={UI programming, downloader tasks, IO operations...}
  ,relation={Futures may be backed by worker pools that execute them.}
]

\pattern [ name={Producer / Consumer}
  ,category={Program structuring}
  ,intent={Pass data items from producers to consumers via a shared buffer}
  ,applicability={Shared memory systems}
  ,status={Implemented library component.}
  ,example={A logger service, where many producers submit log messages to a buffer and a single consumer writes them to a file.}
  ,knownapps={Logging, input processing, pipeline...}
  ,relation={The worker pool uses this pattern to pass along tasks.}
]
\pattern [ name={Thread specific storage}
  ,category={Program structuring}
  ,intent={Provide per-thread singletons.}
  ,applicability={Shared memory systems}
  ,status={Implemented language mechanism.}
  ,example={Store the last exception raised in the current thread.}
%  ,knownapps={}
%  ,relation={}
]

\pattern [ name={Timer: Invoke later}
  ,category={Program structuring}
  ,intent={Invoke a certain operation once at a later point in time.}
%   ,applicability={}
  ,status={Implemented library component}
  ,example={Send an email after a delay of one minute.}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Worker Pool}
  ,category={Performance}
  ,intent={Avoid expensive thread cration by providing a set of threads that can execute arbitrary operations.}
  ,applicability={}
  ,status={Implemented library component}
  ,example={A set of HTTP request handlers in a web server.}
  ,knownapps={The Java Executor service is usually backed by a worker pool.}
%   ,relation={}
]

\pattern [name={Executor framework}
  ,category={Program structuring}
  ,intent={Split task submission from task execution}
%   ,applicability={}
  ,status={Implemented library component.}
  ,example={The Java Executor interface which has implementations for a worker pool or a single thread.}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Publish / Subscribe}
  ,category={Program structuring}
  ,intent={Provide a service for event subscription and delievery, where the publisher doesn't need to know the subscribers.}
%   ,applicability={}
%   ,status={}
  ,example={A GUI button has an event ``clicked'', where the application logic can provide a handler.}
  ,knownapps={GUI frameworks like Java Swing or EiffelVision.}
%   ,relation={}
]

\pattern [name={EiffelVision support}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Handshake}
  ,category={Synchronization primitive}
  ,intent={Send a message from sender to receiver synchronously, where both must wait until the operation has completed.}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Pipeline}
  ,category={Program structuring}
  ,intent={Split processing of input into separate individual stages.}
%   ,applicability={}
%   ,status={}
  ,example={An emailing system that applies a spam filter, database logging, and a virus scan to each incoming email.}
  ,knownapps={Messaging systems, input processing}
  ,relation={This is like a chained producer / consumer}
]

\pattern [name={Timer: Periodic}
  ,category={Program structuring}
  ,intent={Apply an operation repeatedly with a small wait time in between.}
%   ,applicability={}
  ,status={Implemented library component}
  ,example={An emailing application that checks for new messages every five seconds.}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Barrier}
  ,category={Synchronization primitive}
  ,intent={Provide a synchronization point where several threads have to meet before continuing.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={If the computation of a matrix multiplication is split among threads, the barrier can be used to make sure that all threads finish before the result can be used}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Condition Variables}
  ,category={Synchronization primitive}
  ,intent={Wait for a certain condition to become true.}
%   ,applicability={}
  ,status={Implemented language feature, possible library component}
  ,example={When a buffer is empty, a consumer can wait on the is\_not\_empty conditon variable. Producers will signal on this variable when a new item is available.}
  ,knownapps={Preconditions in SCOOP are effectively condition variables, due to their wait semantics.}
%   ,relation={}
]


\pattern [name={TryLock}
  ,category={Synchronization primitive}
  ,intent={Try to acquire a lock, with the option to back off after a certain amount of time.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={Database transactions may get aborted due to a timeout if they can't lock a resource after a certain amount of time.}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Dataflow Network}
  ,category={Program structuring}
  ,intent={Process input in several stages, with the option to process them in parallel at some points.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={A video player application that internally has a file decoder stage, which splits the input in an audio and video part, which then gets further processed.}
%   ,knownapps={}
  ,relation={This is a more generalized form of the pipeline pattern.}
]

\pattern [name={Transactions}
  ,category={Program structuring}
  ,intent={Avoid a deadlock by ``reserving'' a set of objects one at a time.}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Fully Asynch}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Universal Call}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Atomic Operations}
  ,category={Synchronization primitive}
  ,intent={Avoid the use of locks by using hardware-supported atomic operations.}
  ,applicability={Shared memory systems}
  ,status={unsolved}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Monitor}
  ,category={Synchronization primitive}
  ,intent={Ensure that only one thread has access to an object. The thread may also wait on a condition to become true.}
%   ,applicability={}
  ,status={Implemented language mechanism.}
%   ,example={}
%   ,knownapps={}
  ,relation={The monitor pattern can be seen as a combination of single exclusive access and condition variables.}
]

\pattern [name={Read / Write lock}
  ,category={Synchronization primitive}
  ,intent={Allow multiple concurrent readers, but provide exclusive access to a single writer.}
%   ,applicability={}
  ,status={Language limitation}
  ,example={A shared array with frequent concurrent reads can make use of a read / write lock.}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Semaphore}
  ,category={Synchronization primitive}
%   ,intent={Control the amount of threads that may pass a certain section.}
%   ,applicability={}
%   ,status={Possible library component.}
%   ,example={}
%   ,knownapps={}
%   ,relation={Similar to a barrier.}
]

\pattern [name={Active Object}
  ,category={Program structuring}
  ,intent={Assign a thread to an object. Calls to this object correspond to messages with operations to be executed.}
%   ,applicability={}
  ,status={Implemented language mechanism. Implemented library component.}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\pattern [name={Disruptor}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]
% 
\pattern [name={Leader / Follower}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
]

\section {Library}

The library is designed as a set of modules which simplify concurrent programming in SCOOP.
Section ~\ref{sec:tutorial} explains how to use the library for commonly used patterns,
while Section ~\ref{sec:modules} concentrates on the design of the library itself.

\subsection {API tutorial}
\label{sec:tutorial}

\subsubsection{Producer / Consumer}

The producer / consumer example is pretty common in concurrent programming.
At its core is usually a shared buffer.
A producer can add items to the buffer, whereas a consumer removes items from the buffer.

The library class \lstinline!CP_QUEUE! can be used as a shared buffer.
If we want to use \lstinline!STRING! objects to be passed from producer to consumer, we have to declare the queue like this:

\begin{lstlisting}
class PRODUCER_CONSUMER feature

  make
      -- Launch producers and consumers.
    local
      queue: separate CP_QUEUE [STRING, CP_STRING_IMPORTER]
	-- ...
    do
      create queue.make_bounded (10)
	-- ...
    end
end
\end{lstlisting}

Note that there are two generic arguments:
\begin{itemize}
\item The first argument (\lstinline!STRING!) denotes the type of items in the queue.
\item The second argument (\lstinline!CP_STRING_IMPORTER!) defines the import strategy.
\end{itemize}

The import strategy is an important concept of the library.
An import in the SCOOP context means that an object on a separate processor should be copied to the local processor.
This is done recursively for any non-separate reference, i.e. for  \lstinline!STRING! you also have to copy the \lstinline!area! attribute.
The import strategy can be used to tell a component if a given object should be imported, and if yes, how it is done.

In our example we're using the \lstinline!CP_STRING_IMPORTER! to import strings.
An alternative would be to use \lstinline!CP_NO_IMPORTER [STRING]! if we want to disable imports.

The next step we need to do is to define the producer and consumer.

\lstinputlisting [firstline=7] {../../examples/producer_consumer/producer.e}

You may notice three things in this example:

\begin{itemize}
 \item \lstinline!PRODUCER! inherits from \lstinline!CP_STARTABLE!.
 \item The \lstinline!PRODUCER! uses a \lstinline!CP_QUEUE_PROXY! instead of the \lstinline!CP_QUEUE!.
 \item The generated strings are not separate.
\end{itemize}

The classes \lstinline!CP_STARTABLE! and \lstinline!CP_STARTABLE_UTILS! are a useful combination.
They allow to start some operation on a separate object without the need for a specialized wrapper function.

Another nice utility is the \lstinline!CP_QUEUE_PROXY!.
It is part of a pattern which is often used throughout the library - the separate proxy \todo{add reference}.
Basically it allows to access a separate queue without the need to deal with separate references.

The really interesting thing however is that the producer can generate strings on its local processor.
Usually this is not possible, because if the string is later passed to a consumer object, the latter needs to lock the producer in order to get access to the string.
But in this case we instructed the queue object to import all string objects. During a call to \lstinline!queue_wrapper.put(item)! the following happens:
\begin{itemize}
 \item The producer waits until it gets exclusive access to the queue.
 \item The separate call is executed. Because \lstinline!item! is a non-separate reference, the call is synchronous and lock passing happens.
 \item The queue object imports the separate string, creating a local copy.
 \item The separate call terminates, both processors can proceed autonomously.
\end{itemize}
Creating the strings on a separate processor is therefore unnecessary.

The import trick avoids a lot of unnecessary thread creation:
Instead of creating a new processor for every single produced item we just copy it, which is much faster for small objects.

The consumer is basically the same as the producer, except for the feature \lstinline!start!:

\begin{lstlisting}
class
  CONSUMER
--...
  
	start
			-- Consume `item_count' items.
		local
			i: INTEGER
			item: STRING
		do
			from
				i := 1
			until
				i > item_count
			loop
				queue_wrapper.consume

				check attached queue_wrapper.last_consumed_item as l_item then

						-- Note that `item' is not declared as separate, because it has been
						-- imported automatically.
					item := l_item
					print (item + " // Consumer " + identifier.out + ": item " + i.out + "%N")
				end
				i := i + 1
			end
		end
end
\end{lstlisting}

You might notice again that the consumed string is not declared as separate.
This is again because of the import mechanism within \lstinline!CP_QUEUE!.

The last thing we need to do is to create and launch the producers and consumers in the main application:

\lstinputlisting [firstline=7] {../../examples/producer_consumer/producer_consumer.e}


\subsubsection{Server thread}

In networking you often need a dedicated thread that listens on a socket.
In a SCOOP environment it is not hard to create such a processor, but it is hard to stop it.
The main problem is that the server processor will run its own main loop, and other threads ususally never get exclusive access to call some feature \lstinline!stop!.

The library addresses this issue with the \lstinline!CP_INTERMITTENT_PROCESS!.
This class defines a special main loop, where other processors can access the object after every iteration.

To use \lstinline!CP_INTERMITTENT_PROCESS! you need to inherit from it and implement the deferred feature \lstinline!step!.
The following example defines a simple echo server that just listens and replies with the same string:

\lstinputlisting [firstline=7] {../../examples/echo_server/echo_server.e}

To break out of the main loop, you need to set \lstinline!is_stopped! to \lstinline!True!.
This can be done from within the \lstinline!CP_INTERMITTENT_PROCESS! or from a separate processor by calling \lstinline!stop!.

To start the echo server you can use \lstinline!CP_STARTABLE_UTILS! and the feature \lstinline!asynch_start!:

\lstinputlisting [firstline=7] {../../examples/echo_server/echo_application.e}

\subsubsection{Futures}

A future is a computation which may run asynchronously, possibly returning a result.
The future is a very popular pattern in other languages like Java.

The idea is that the computation is encapsulated in an object which may be executed by another thread.
If there's a result to the computation, the client thread also gets a token back to access the result at some point in the future.
This token is usually called ``Future'' or ``Promise''.

The library mechanism to support futures are the class hierarchies rooted at \lstinline!CP_TASK!, \lstinline!CP_BROKER! and \lstinline!CP_EXECUTOR!.

The \lstinline!CP_DEFAULT_TASK! class is used to define the operation.
To use it you need to inherit from it and implement \lstinline!run! and \lstinline!make_from_separate!.
The latter is needed because SCOOP doesn't allow shared access to objects, which is why a \lstinline!CP_TASK! needs to be imported from one processor to another.
If the operation is returning a result, it is necessary to inherit from \lstinline!CP_COMPUTATION! and implement \lstinline!computed!.

\lstinline!CP_EXECUTOR! is used to submit a task to be executed.
The main implementation is \lstinline!CP_TASK_WORKER_POOL!, which is using a worker pool to execute \lstinline!CP_TASK! objects.
The executor shoud be accessed using a local \lstinline!CP_EXECUTOR_PROXY! and \lstinline!CP_FUTURE_EXECUTOR_PROXY!, which simplify access to the \lstinline!separate CP_EXECUTOR! and also initialize the Promise object.

The \lstinline!CP_BROKER! serves as the token to store the status of the computation and a possible result.
It is created on a separate processor, such that both the client and the task object can access it without the risk of a deadlock.
If you use \lstinline!CP_EXECUTOR_PROXY!, you can submit a task and receive a token object by using \lstinline!put_with_broker!.

\todo{integrate example}


\subsection {Architecture and modules}
\label{sec:modules}

The library consists of several modules, which often build on each other.

\subsection{Import}

The import module is one of the most important mechanisms in the library.
It consists of all classes in the directory \dir{library/import}.

The main class is the deferred \lstinline!CP_IMPORT_STRATEGY [G]!, which has the simple interface:


\lstinputlisting [firstline=7] {../../library/import/cp_import_strategy.e}

By implementing \lstinline!import!, descendants can decide if an object of type \lstinline!G! shall be imported and if yes, how it's done.

The class \lstinline!CP_NO_IMPORTER[G]! is the default class to disable import and just perform a reference copy.
Every other importer can inherit from \lstinline!CP_IMPORTER!, which narrows the return type of \lstinline!import! to a non-separate \lstinline!G!.

Because writing an extra importer for every importable object may be tedious, there's a support class \lstinline!CP_IMPORTABLE!:

\lstinputlisting [firstline=7] {../../library/import/cp_importable.e}

That way an import function can be written right inside the class that needs to be imported.
There are two main import classes that make use of it: \lstinline!CP_DYNAMIC_TYPE_IMPORTER! and \lstinline!CP_STATIC_TYPE_IMPORTER!.
The latter uses bounded genericity to directly create an object of type \lstinline!G!.
This has the drawback however that the type is statically \lstinline!G!, even if the argument to \lstinline!import! was of a subtype of \lstinline!G!.

The \lstinline!CP_DYNAMIC_TYPE_IMPORTER! tries to avoid this problem by using reflection.
This introduces a new problem with respect to void safety however, as the new object will not be initialized.
Therefore it is strongly advised to declare \lstinline!make_from_separate! as a creation procedure for every descendant of \lstinline!CP_IMPORTABLE!.

Another problem of the \lstinline!CP_DYNAMIC_TYPE_IMPORTER! are the invariants of an object.
There's a short time interval between the creation of an object (using reflection) and the call to \lstinline!{CP_IMPORTABLE}.make_from_separate! where the invariants are broken.
Due to this, it is not possible to have invariants in a class that will be imported using the dynamic type importer.

In the future, there will hopefully exist an import routine natively supported by the SCOOP runtime.
In that case \lstinline!CP_IMPORTER! can be made effective and use the native import, and all its descendants will become obsolete.


Other components of the library often use the import module via bounded genericity.
The class \lstinline!CP_QUEUE! for example has the ability to import objects, and it's class header looks like this:
\begin{lstlisting}
class
  [G, IMPORTER -> CP_IMPORT_STRATEGY [G] create default_create end]
feature
  ...
end
\end{lstlisting}
That way a user can decide on the precise semantics of the import strategy by just declaring the right type.

\subsection{Separate proxy}

The separate proxy pattern is a SCOOP specific mechanism.
The goal of the pattern is to provide a nice interface to a separate object, by providing a processor-local proxy which hides the separate reference.

Usually the pattern consists of three classes:
\begin{enumerate} [label=(\arabic*)]
 \item\label{item:sep-proxy:first} The class for the actual separate object.
 \item\label{item:sep-proxy:second} A class that provides helper functions to access a separate object of type \ref{item:sep-proxy:first}, usually with the ending \lstinline!_UTILS!.
 \item\label{item:sep-proxy:third} A proxy class with the a similar interface as \ref{item:sep-proxy:first}, usually ending on \lstinline!_PROXY!.
 Using \ref{item:sep-proxy:second}, the proxy forwards all calls to an object of type \ref{item:sep-proxy:first}.
\end{enumerate}

\todo{A little diagram showing the class relations.}

It is possible to add a fourth, deferred class that just defines the interface for \ref{item:sep-proxy:first} and \ref{item:sep-proxy:third}.
However, there's an inconsistency: 
Any precondition in \ref{item:sep-proxy:first} which references \lstinline!Current! needs to be converted to a wait condition in \ref{item:sep-proxy:third} that references \ref{item:sep-proxy:first}.
Furthermore, not all features in the business class may be necessary in the proxy, and the proxy itself may add some more features such as compound actions.

Unfortunately this pattern cannot be fully turned into a module, because it's highly dependent on the precise interface of the business class.
There is however some support in the library: 
\lstinline!CP_PROXY! defines the creation procedure and the attributes \lstinline!subject! for a business class object and \lstinline!utils! for a helper object.

The following example shows a general recipe on how to create a separate proxy for the small class \lstinline!EXAMPLE!:

\begin{lstlisting}
deferred class
  EXAMPLE [G]

feature -- Status report

  is_available: BOOLEAN
      -- Is `item' available?
  
feature -- Access

  item: separate G
      -- Item in `Current'.
    require
      available: is_available
    deferred
    end

feature -- Element change

  put (a_item: separate G)
      -- Set `item' to `a_item'.
    deferred
    end

end
\end{lstlisting}

First we need to create the helper class.
This is done according to these rules:
 \begin{itemize}
  \item The name should be \lstinline!EXAMPLE_UTILS!.
  \item The generic arguments are the same as in \lstinline!EXAMPLE!
  \item Any feature to access the separate \lstinline!EXAMPLE! object can be prefixed by \lstinline!example_!.
  This helps to avoid name clashes if someone wants to inherit from \lstinline!EXAMPLE_UTILS!
  \item The first argument of each feature is \lstinline!example: separate EXAMPLE [G]!.
  All other arguments are the same as the ones in the corresponding feature in \lstinline!EXAMPLE!.
  \item Preconditions in \lstinline!EXAMPLE! should be rewritten as wait conditions with the same meaning in \lstinline!EXAMPLE_UTILS!.
  \item If there's a non-expanded return type to a feature, you can decide if it should be declared separate in \lstinline!EXAMPLE_UTILS! or if it should be imported.
 \end{itemize}

\begin{lstlisting}
class
  EXAMPLE_UTILS [G]
  
feature -- Access

  example_item (example: separate EXAMPLE [G]): separate G
      -- Get the item from `example'.
      -- May block if not yet available.
    require
      available: example.is_available
    do
      Result := example.item
    end

feature -- Element change
 
  example_put (example: separate EXAMPLE [G]; item: separate G)
      -- Put `item' into `example'.
    do
      example.put (item)
    end
end
\end{lstlisting}

In this example we also dropped the feature \lstinline!is_available!, because it's not considered to be important for separate clients.

The proxy class has also has some simple rules:

 \begin{itemize}
  \item The name should be \lstinline!EXAMPLE_PROXY!.
  \item The generic arguments are the same as in \lstinline!EXAMPLE!
  \item The class can inherit from \lstinline!CP_PROXY [EXAMPLE [G], EXAMPLE_UTILS [G]]! and declare \lstinline!make! as a creation procedure.
  \item The feature names and arguments are the same as in \lstinline!EXAMPLE!.
  \item Preconditions in \lstinline!EXAMPLE! are usually not present in \lstinline!EXAMPLE_PROXY!. They are wait conditions in \lstinline!EXAMPLE_UTILS! instead.
  \item Every feature implementation makes use of \lstinline!utils! to forward the request to the \lstinline!subject!.
 \end{itemize}

\begin{lstlisting}
class
  EXAMPLE_PROXY [G]

inherit
  CP_PROXY [EXAMPLE [G], EXAMPLE_UTILS [G]]

create
  make
  
feature -- Access

  item: separate G
      -- Item in the example object.
      -- May block if not yet available.
    do
      Result := utils.cell_item (subject)
    end

feature -- Element change

  put (a_item: separate G)
      -- Set `item' to `a_item'.
    do
      utils.cell_put (subject, a_item)
    end

end
\end{lstlisting}
 
\subsection{Queue}

The queue module is a simple queue implementation.
It uses the separate proxy pattern, which means that it consists of three classes:

\begin{itemize}
 \item \lstinline!CP_QUEUE!
 \item \lstinline!CP_QUEUE_UTILS!
 \item \lstinline!CP_QUEUE_PROXY!
\end{itemize}

The first one provides the actual queue, but internally it just relies on \lstinline!ARRAYED_QUEUE!.
The class \lstinline!CP_QUEUE_PROXY! can be used to access such a shared, separate queue without having to deal with separate references.

The interesting thing about this queue implementation is that it makes use of the import module.
Along with the generic argument \lstinline!G! you can also provide an \lstinline!CP_IMPORT_STRATEGY [G]!.
The import then happens automatically in both the queue and its proxy.

\subsection{Process}

The process module provides a set of classes that all implement some sort of skeleton for a main loop.

\todo{more text}

\subsection{Worker pool}

The worker pool module provides support classes to build a worker pool.
It makes use of the queue module to store the work items.

The module consists of three classes:

\begin{itemize}
 \item \lstinline!CP_WORKER!
 \item \lstinline!CP_WORKER_POOL!
 \item \lstinline!CP_WORKER_FACTORY!
\end{itemize}

The last one is just an factory class to create the user-defined \lstinline!CP_WORKER! objects.

The deferred class \lstinline!CP_WORKER! has a predefined main loop, where the object first checks if it needs to terminate, then grabs a new work item, and processes it.
The processing step is deferred and needs to be implemented by the user.
Implemented

The \lstinline!CP_WORKER_POOL! is the central management instance.
Its primary task is to accept new work items from clients, but it can also be used to adjust the number of workers in the pool and to terminate all workers.
The \lstinline!CP_WORKER_POOL! also implements the separate proxy pattern, which means that clients should access it through \lstinline!CP_WORKER_POOL_PROXY!.

\subsection{Broker}



\subsection{Executor and CP\_TASK}



\section {Individual patterns}
% Description of a few patterns

\subsection{Producer / Consumer and Pipeline}

\subsection{Worker pool}

\subsection{Future}

\subsection{Evaluation and Benchmarks}


\section{Conclusion}

\todos
\end{document}          
