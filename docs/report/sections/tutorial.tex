
\section {API tutorial}
\label{sec:tutorial}

The library has several components which can be used for various tasks in concurrent programming.
This API tutorial therefore consists of three, mostly unrelated sections.
Each section describes a concurrency problem and how the library can be used to solve it.

All programming code used in this section originally comes from the example applications in the repository \cite{web:repository}.

\subsection{Producer / Consumer}

The producer / consumer example is pretty common in concurrent programming.
At its core is usually a shared buffer.
A producer can add items to the buffer, whereas a consumer removes items from the buffer.

The library class \lstinline!CP_QUEUE! can be used as a shared buffer.
If we want to use \lstinline!STRING! objects to be passed from producer to consumer, we have to declare the queue like this:

\begin{lstlisting}
class PRODUCER_CONSUMER feature

  make
      -- Launch producers and consumers.
    local
      queue: separate CP_QUEUE [STRING, CP_STRING_IMPORTER]
	-- ...
    do
      create queue.make_bounded (10)
	-- ...
    end
end
\end{lstlisting}

Note that there are two generic arguments:
\begin{itemize}
\item The first argument (\lstinline!STRING!) denotes the type of items in the queue.
\item The second argument (\lstinline!CP_STRING_IMPORTER!) defines the import strategy (see Section \ref{sec:concepts:import}).
  It teaches the queue how to import a string object.
\end{itemize}

% The import strategy is an important concept of the library.
% An import in the SCOOP context means that an object on a separate processor should be copied to the local processor.
% This is done recursively for any non-separate reference, i.e. for  \lstinline!STRING! you also have to copy the \lstinline!area! attribute.
% The import strategy can be used to tell a component if a given object should be imported, and if yes, how it is done.

In our example we decided to import every string object.
% In our example we're using the \lstinline!CP_STRING_IMPORTER! to import strings.
An alternative would be to use \lstinline!CP_NO_IMPORTER [STRING]! and deal with separate references instead.

The next step is to define the producer and consumer.

\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={The producer class.}]
class
	PRODUCER

inherit
	CP_STARTABLE

create
	make

feature {NONE} -- Initialization

	make (a_queue: separate CP_QUEUE [STRING, CP_STRING_IMPORTER]; a_identifier: INTEGER; a_item_count: INTEGER)
			-- Initialization for `Current'.
		do
			identifier := a_identifier
			item_count := a_item_count
			create queue_wrapper.make (a_queue)
		end

	queue_wrapper: CP_QUEUE_PROXY [STRING, CP_STRING_IMPORTER]
			-- A wrapper object to a separate queue.

	identifier: INTEGER
			-- Identifier of `Current'.

	item_count: INTEGER
			-- Number of items to produce.

feature -- Basic operations

	start
			-- Produce `item_count' items.
		local
			i: INTEGER
			item: STRING
		do
			from
				i := 1
			until
				i > item_count
			loop
					-- Note that there's no need to declare `item' as 
					-- separate, because it will be imported anyway.
				item := "Producer: " + identifier.out + ": item " + i.out
				queue_wrapper.put (item)
				i := i + 1
			end
		end

end
\end{lstlisting}

You may notice three things in this example:

\begin{itemize}
 \item \lstinline!PRODUCER! inherits from \lstinline!CP_STARTABLE!.
 \item The \lstinline!PRODUCER! uses a \lstinline!CP_QUEUE_PROXY! instead of the \lstinline!CP_QUEUE!.
 \item The generated strings are not separate.
\end{itemize}

The classes \lstinline!CP_STARTABLE! and \lstinline!CP_STARTABLE_UTILS! are a useful combination.
They allow to start some operation on a separate object without the need for a specialized wrapper function.

\lstinline!CP_QUEUE_PROXY! is part of the Separate Proxy pattern \patternref{SP} (see Section \ref{sec:separate-proxy}).
It is useful to access a separate object without having to deal with separate references.

The fact that strings can be generated on the local processor is probably the most interesting observation.
Usually it is necessary when using SCOOP to create shared data on its own processor.
As we're using the import mechanism however this is not necessary and would be even wasteful.

% Usually this is not possible, because if the string is later passed to a consumer object, the latter needs to lock the producer in order to get access to the string.
% But in this case we instructed the queue object to import all string objects. During a call to \lstinline!queue_wrapper.put(item)! the following happens:
% \begin{itemize}
%  \item The producer waits until it gets exclusive access to the queue.
%  \item The separate call is executed. Because \lstinline!item! is a non-separate reference, the call is synchronous and lock passing happens.
%  \item The queue object imports the separate string, creating a local copy.
%  \item The separate call terminates, both processors can proceed autonomously.
% \end{itemize}
% Creating the strings on a separate processor is therefore unnecessary.

% The import trick avoids a lot of unnecessary thread creation:
% Instead of creating a new processor for every single produced item we just copy it, which is much faster for small objects.

The consumer is the same as the producer except for the feature \lstinline!start!:

\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={The consumer class.}]
class
  CONSUMER
  
inherit
  CP_STARTABLE

  -- Initialization omitted...

feature -- Basic operations

	start
			-- Consume `item_count' items.
		local
			i: INTEGER
			item: STRING
		do
			from
				i := 1
			until
				i > item_count
			loop
				queue_wrapper.consume

				check attached queue_wrapper.last_consumed_item as l_item then

						-- Note that `item' is not declared as separate
					item := l_item
					print (item + " // Consumer " + identifier.out 
					  + ": item " + i.out + "%N")
				end
				i := i + 1
			end
		end
end
\end{lstlisting}

Again, there's no need to declare the consumed string as separate, thanks to the import mechanism.

% You might notice again that the consumed string is not declared as separate.
% This is again because of the import mechanism within \lstinline!CP_QUEUE!.

The only thing left now is to create and launch the producers and consumers in the main application.
Note that \lstinline!PRODUCER_CONSUMER! inherits from \lstinline!CP_STARTABLE_UTILS! such that it can use \lstinline!async_start! to start both the consumer and producer threads.

\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={The producer / consumer application root class.}]
class
	PRODUCER_CONSUMER

inherit
	CP_STARTABLE_UTILS

create
	make

feature {NONE} -- Initialization

	make
			-- Launch the producer and consumers.
		local
			l_queue: separate CP_QUEUE [STRING, CP_STRING_IMPORTER]
			l_producer: separate PRODUCER
			l_consumer: separate CONSUMER
		do
			print ("%NStarting producer/consumer example. %N%N")

				-- Create a shared bounded queue for data exchange.
			create l_queue.make_bounded (queue_size)

				-- Create and launch the consumers.
			across 1 |..| consumer_count as i loop
				create l_consumer.make (l_queue, i.item, items_per_consumer)
				async_start (l_consumer)
			end

				-- Create and launch the producers.
			across 1 |..| producer_count as i loop
				create l_producer.make (l_queue, i.item, items_per_producer)
				async_start (l_producer)
			end
		end

feature -- Constants

	queue_size: INTEGER = 5
	producer_count: INTEGER = 10
	consumer_count: INTEGER = 10
	items_per_producer: INTEGER = 20
	items_per_consumer: INTEGER = 20

invariant
	equal_values: producer_count * items_per_producer = consumer_count * items_per_consumer
end
\end{lstlisting}

\subsection{Server thread}
\label{sec:echo-server}

In network server programming it is common to have a dedicated thread listening on a socket.
In a SCOOP environment it is not hard to create such a processor, but it is hard to stop it.
The main problem is that the server will run its own main loop, and other processors never get exclusive access to call a feature like \lstinline!stop!.

The library addresses this issue with \lstinline!CP_INTERMITTENT_PROCESS!.
The class defines a special main loop using the Asynchronous Self-Call pattern \patternref{ASC}.

To use \lstinline!CP_INTERMITTENT_PROCESS! you need to inherit from it and implement the deferred feature \lstinline!step!.
The following example defines a simple echo server that just listens on a socket and replies with the same string:

\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={The echo server class.}]
class
	ECHO_SERVER

inherit

	CP_INTERMITTENT_PROCESS
		redefine
			cleanup
		end

create
	make

feature {NONE} -- Initialization

	make
			-- Initialization for `Current'.
		do
				-- Create the socket on the specified port.
			create socket.make_server_by_port (2000)
				-- Set an accept timeout.
			socket.set_accept_timeout (500)
				-- Enable the socket.
			socket.listen (5)
		end

feature -- Basic operations

	cleanup
			-- <Precursor>
		do
			socket.cleanup
		end

	stop
			-- Stop the current processor.
		do
			is_stopped := True
		end

		
	step
			-- <Precursor>
		local
			l_received: STRING
		do
				-- Accept a new message.
			socket.accept
			
				-- In case of an accept timeout `accepted' is Void.
			if attached socket.accepted as l_answer_socket then

					-- Read the message.
				l_answer_socket.read_line
				l_received := l_answer_socket.last_string

					-- Generate and send the answer.
				l_answer_socket.put_string (l_received)
				l_answer_socket.put_new_line
				l_answer_socket.close
			end
		end

feature {NONE} -- Implementation

	socket: NETWORK_STREAM_SOCKET
			-- The server network socket.

end
\end{lstlisting}
The accept timeout is important in this example.
It ensures that the server processor periodically breaks free of its wait condition while listening and therefore has a chance to finish the \lstinline!step! feature.

The echo server can be started with \lstinline!{STARTABLE_UTILS}.async_start! and stopped with the feature \lstinline!stop!.
Thanks to the special loop construct used in \lstinline!CP_INTERMITTENT_PROCESS!, stopping the echo server also works when called from another processor.

\subsection{Worker Pool and Futures}

This section describes how to use a worker pool for I/O tasks.
The application defines two operations on text files: reading a file and appending a string to a file.
The classes to represent these operations are \lstinline!FILE_APPENDER_TASK! and \lstinline!FILE_READER_TASK!.

The file reader task is implemented with the future module from the library.
The library has the class \lstinline!CP_COMPUTATION! which represents futures, i.e. asynchronous tasks that return a result.
The \lstinline!FILE_READER_TASK! therefore needs to inherit from \lstinline!CP_COMPUTATION!.

The file appender task doesn't return a result.
Therefore it has to inherit from \lstinline!CP_DEFAULT_TASK!.
This inheritance is necessary to be able to submit it to a worker pool later.

The two classes are shown in Listing \ref{code:file-tasks}.

\begin{lstlisting}[language=OOSC2Eiffel, label={code:file-tasks}, captionpos=b, caption={The file reader and appender classes.}]
class
	FILE_READER_TASK
inherit
	CP_COMPUTATION [STRING]

create
	make, make_from_separate

feature {NONE} -- Initialization

	make (a_path: STRING)
			-- Create a new task to read the content from `a_path'.
		do
			path := a_path
		end

feature {CP_DYNAMIC_TYPE_IMPORTER} -- Initialization

	make_from_separate (other: separate like Current)
			-- <Precursor>
		do
			create path.make_from_separate (other.path)
			promise := other.promise
		end

feature -- Access

	path: STRING
			-- The path of the file to read from.

feature -- Basic operations

	computed: STRING
			-- <Precursor>
		local
			l_file: PLAIN_TEXT_FILE
			l_content: STRING
		do
			create l_file.make_open_read (path)
			l_file.read_stream (l_file.count)
			Result := l_file.last_string
			l_file.close
		end
end

class
	FILE_APPENDER_TASK
inherit
	CP_DEFAULT_TASK

    -- Initialization similar to FILE_READER_TASK.
	
feature -- Access

	path: STRING
			-- The path of the file to write to.

	content: STRING
			-- The content to be written.

feature -- Basic operations

	run
			-- <Precursor>
		local
			l_file: PLAIN_TEXT_FILE
		do
			create l_file.make_open_append (path)
			l_file.put_string (content)
			l_file.close
		end
end
\end{lstlisting}

The main algorithm needs to be defined in \lstinline!computed! or \lstinline!run!, respectively.
Additionally, the feature \lstinline!make_from_separate! has to be defined.
This feature is required to import task objects from the client to the worker pool processor (see Section \ref{sec:concepts:import} for the import concept).

\lstinline!CP_EXECUTOR! defines an interface to submit and execute task objects.
The main implementation is \lstinline!CP_TASK_WORKER_POOL!.
The executor is shipped with a Separate Proxy \patternref{SP}, which means users can access it via \lstinline!CP_EXECUTOR_PROXY! or \lstinline!CP_FUTURE_EXECUTOR_PROXY!.
These two proxy classes also initialize the promise object, which is a handle to the asynchronous operation that can be used to wait for its termination or to retrieve the result when it's available.

Listing \ref{code:io-worker-pool} shows how a worker pool is used to submit file read and append tasks.

\begin{lstlisting}[language=OOSC2Eiffel, label={code:io-worker-pool}, captionpos=b, caption={Using a worker pool for futures and asynchronous tasks.}]
class
	IO_WORKER_POOL

create
	make

feature -- Constants

	path: STRING = "a.txt"
	
	hello_world: STRING = "Hello World%N"

feature {NONE} -- Initialization

	make
			-- Initialization for `Current'.
		do
				-- Create the worker pools.
			create worker_pool.make (100, 4)
			create executor.make (worker_pool)

				-- Run the example
			single_read_write

				-- Stop the executor. This is necessary such that 
				-- the application can terminate.
			executor.stop
		end

feature -- Basic operations

	single_read_write
			-- Perform a single write operation on a file.
		local
			write_task: FILE_APPENDER_TASK
			write_task_promise: CP_PROMISE_PROXY

			read_task: FILE_READER_TASK
			read_task_promise: CP_RESULT_PROMISE_PROXY [STRING, CP_STRING_IMPORTER]

			l_result: detachable STRING
		do
				-- Execute a file append task first.
			create write_task.make (path, hello_world)

				-- Submit the task and get a promise object.
			write_task_promise := executor.put_with_promise(write_task)

				-- Wait for the task to finish.
			write_task_promise.await_termination

				-- It is possible to check for IO exceptions.
			check no_exception: 
			  not write_task_promise.is_exceptional 
			end


				-- Now execute a read task.
			create read_task.make (path)

				-- Submit the task and get a promise.
			read_task_promise := executor.put_future (read_task)

				-- The promise can be used to retrieve the result.
				-- Note that the statement may block if the result
				-- is not ready yet.
			l_result := read_task_promise.item

				-- Check if the read-write cycle worked as expected.
% 			check correct_result: l_result ~  hello_world end
		end

feature {NONE} -- Implementation

	worker_pool: separate CP_TASK_WORKER_POOL
			-- The worker pool that executes the IO tasks.

	executor: CP_FUTURE_EXECUTOR_PROXY[STRING, CP_STRING_IMPORTER]
			-- The executor proxy for to submit tasks.

end
\end{lstlisting}

Submitting tasks to the executor and dealing with the asynchronous result is pretty straightforward.
Some calls to the promise object are blocking however, e.g. \lstinline!await_termination! or \lstinline!item!, if the asynchronous task has not finished yet.

The library ensures that no exception can escape the task object and crash the worker pool or the client code.
Clients can check if an exception happened with the query \lstinline!is_exceptional! on the promise object.
The exception trace, if any, is also available to the client with the query \lstinline!last_exception_trace!.

An important measure is to stop the executor when the application wants to terminate.
Otherwise the workers will continue to wait for incoming tasks, preventing the process to shut down.
