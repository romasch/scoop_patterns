\section {Pattern overview}
\label{sec:pattern_overview}
% Overview of all patterns

\subsection{Data-centric patterns}

\pattern [name={Producer / Consumer}
  ,label={P/C}
  ,category={Program structuring}
  ,intent={Provide a synchronized shared buffer. Producer threads put items into the buffer, and consumers remove items.}
  ,applicability={When participants should not know each other. Also applicable if there's no one-to-one relation between producers and consumers or when buffering is desired.}
  ,status={Implemented library component}
  ,example={A logger service where many producers submit log messages to a buffer and a single consumer writes them to a file.}
  ,knownapps={Very widely used. E.g. logging, input processing, buffering web server requests.}
  ,relation={The Worker Pool \patternref{WP} uses this pattern for its task queue. Pipeline \patternref{PL} and Dataflow Networks \patternref {DFN} are chained Producer / Consumer instances.}
 ,references={\cite[p. 87]{book:java-concurrency}, \cite[p. 53]{book:ppl}}
]

\pattern [name={Pipeline}
  ,label={PL}
  ,category={Program structuring}
  ,intent={Process data in several independent stages.}
  ,applicability={When the input consist of a stream of data where several processing steps need to be performed.}
  ,status={Possible library component}
  ,example={An emailing system that applies a spam filter, database logging, and a virus scan to each incoming email.}
  ,knownapps={Messaging systems, multimedia streaming (receive - decode - display)}
  ,relation={The Producer / Consumer pattern \patternref{P/C} is used between two stages. Pipeline is a special form of Dataflow Network \patternref{DFN}.}
 ,references={\cite[p. 305]{book:cpj}, \cite[p. 253]{book:spp}, \cite[p. 53]{book:ppl}}
]

\pattern [name={Dataflow Network}
  ,label={DFN}
  ,category={Program structuring}
  ,intent={Process data in independent stages, with the option to branch and merge data streams.}
  ,applicability={When the input consists of a stream of data which allows for parallel processing.}
  ,status={Possible library component}
  ,example={A video player application that internally has a file decoder stage, which splits the input in an audio and video part for further processing.}
  ,knownapps={The borealis engine \cite{web:borealis}.}
  ,relation={The pattern is related to Pipeline \patternref{PL}. In Dataflow Network however data can be split and forwarded to two different stages and maybe merged again later.}
 ,references={\cite[p. 305]{book:cpj}, \cite[p. 261]{book:spp}}
]

\pattern [name={Exchanger}
  ,label={EXC}
  ,category={Program structurings}
  ,intent={Exchange two objects between two threads atomically.}
  ,applicability={When synchronization and atomicity is required.}
  ,status={Possible library component.}
  ,example={A logger with two buffers: One is used by clients to submit messages, the other is used by the logger to write messages. When the latter is empty and the former is full the exchange happens.}
  ,knownapps={ - }
  ,relation={Similar to Synchronous Message Passing, except that data passes in both directions.}
  ,references={\cite[p. 101]{book:java-concurrency}, \cite[p. 231]{book:cpj}}
]

\subsection{Task-centric patterns}

\pattern [name={Worker Pool}
  ,label={WP}
  ,category={Performance}
  ,intent={Avoid expensive thread creation by providing a set of threads that can execute arbitrary operations.}
  ,applicability={When there are a lot of small tasks that may be executed in parallel.}
  ,status={Implemented library component}
  ,example={A set of HTTP request handlers in a web server.}
  ,knownapps={Often used in server applications, e.g. databases, HTTP servers, web services.}
  ,relation={Producer / Consumer \patternref{P/C} is used to pass along task objects. Worker Pool is usually an implementation of the Executor Framework \patternref{EF}.}
 ,references={\cite[p. 117]{book:java-concurrency}, \cite[p. 167]{book:java-concurrency}, \cite[p. 290]{book:cpj},  \cite[p. 61]{book:ppl}, \cite{paper:tpl}}
]

\pattern [ name={Future}
  ,label={FUT}
  ,category={Program structuring, Performance}
  ,intent={Run a task asynchronously and fetch the result later.}
  ,applicability={When a computation may be run in parallel, but creating an extra thread is too expensive.}
  ,status={Implemented library component}
  ,example={A web browser which starts download tasks for image files in parallel to rendering an HTML file.}
  ,knownapps={In UI programming for long-running background tasks, or parallelization of numerical computations.}
  ,relation={Futures may be backed by a Worker Pool \patternref{WP} that execute them.}
  ,references={\cite[p. 125]{book:java-concurrency}, \cite[p. 332]{book:cpj}, \cite[p. 36]{book:ppl}, \cite{paper:tpl}}
  ,comment={The \emph{wait by necessity} semantics of SCOOP \cite{web:scoop} also correspond to the Future pattern.}
]

\pattern [name={Executor Framework}
  ,label={EF}
  ,category={Program structuring}
  ,intent={Split task submission from task execution.}
  ,applicability={When the task execution strategy should be flexible, e.g. using a worker pool or creating a new thread per task.}
  ,status={Implemented library component}
  ,example={The Java Executor interface, where descendants can decide wether a submitted Runnable object is executed in the current thread, in a new thread, or by a worker pool.}
  ,knownapps={Java Executor interface, Microsoft Task Parallel Library}
  ,relation={The Worker Pool \patternref{WP} is an implementation of the Executor Framework.}
  ,references={\cite[p. 117]{book:java-concurrency}, \cite[p. 289]{book:cpj}}
]

\pattern [name={Timer: Periodic}
  ,label={TP}
  ,category={Program structuring}
  ,intent={Apply an operation repeatedly in regular intervals.}
  ,applicability={When an operation, which can be executed in parallel to the application's main thread, needs to be applied repeatedly.}
  ,status={Implemented library component}
  ,example={An email client that checks for new messages every five seconds.}
  ,knownapps={Message polling, buffer flushes, background log writes, heartbeat messages, cron jobs.}
  ,relation={Similar to Active Object \patternref{AO}, but it schedules just one operation repeatedly.}
  ,references={\cite[p. 123]{book:java-concurrency}, \cite[p. 298]{book:cpj}}
]

\pattern [ name={Timer: Invoke Later}
  ,label={TIL}
  ,category={Program structuring}
  ,intent={Invoke a certain operation at a later point in time.}
  ,applicability={When it is necessary to wait a bit before executing an operation.}
  ,status={Implemented library component}
  ,example={Send an email after a delay of one minute, during which the user can still press a cancel button.}
  ,knownapps={``Grace periods'' to cancel actions, robotics control, alarm clocks.}
  ,relation={ - }
  ,references={\cite[p. 123]{book:java-concurrency}, \cite[p. 297]{book:cpj}}
]

\subsection{I/O patterns}

\pattern [name={Half-Sync / Half-Async}
  ,label={HS/HA}
  ,category={Program structuring}
  ,intent={Simplify asynchronous event handling. A thread or an interrupt handler listens for incoming messages and puts them in a synchronized queue. Worker threads then retrieve and handle the messages.}
  ,applicability={When the application must react to several event sources at the same time.}
  ,status={not covered}
  ,example={The network stack in most UNIX system is implemented like this. A network socket is the ``queue'' which gets filled by interrupt handlers. Application threads take care of handling the data.}
  ,knownapps={Network sockets, web servers.}
  ,relation={ - }
  ,references={\cite[p. 423]{book:posa2}}
]

\pattern [name={Leader / Followers}
  ,label={L/F}
  ,category={Performance, Program structuring}
  ,intent={Reduce synchronization overhead when using a thread pool to handle requests on I/O sockets. A leader thread receives a request, promotes the next leader, and then handles the request.}
  ,applicability={When there are hundreds of I/O sockets.}
  ,status={not covered}
  ,example={A web server for a high volume website serving thousands of connections at the same time.}
  ,knownapps={Online Transaction Processing (OLTP) applications.}
  ,relation={Compared to Half-Sync / Half-Async \patternref{HS/HA} it avoids the synchronization overhead of a shared queue.}
  ,references={\cite[p. 447]{book:posa2}, \cite{paper:leader-follower}}
]

\pattern [name={Disruptor}
  ,label={DIS}
  ,category={Performance, Program structuring}
  ,intent={Provide a high-performance ring buffer with a single producer and multiple readers, each assigned to a thread. Readers can have dependencies to other readers and change buffer entries.}
  ,applicability={When very high throughput in an I/O application is required.}
  ,status={not covered}
  ,example={An OLTP system where the producer listens on a socket for new requests. Then there's a reader for each of the following tasks: logging, unmarshalling, request handling.}
  ,knownapps={LMAX Exchange uses this pattern for their trading platform.}
  ,relation={Similar to Half-Synch/Half-Asynch \patternref{HS/HA}, but buffer entries may be modified in place and accessed by several threads.}
 ,references={\cite{paper:disruptor}}
]

\subsection{Miscellaneous patterns}

\pattern [name={Active Object}
  ,label={AO}
  ,category={Program structuring}
  ,intent={Pair an object with its own thread. Clients access the active object through a proxy which transforms feature calls to asynchronous messages. 
  The active object runs a main loop where it schedules requests from clients and runs its own code.}
  ,applicability={When access to a shared resource can be guarded by an object, or when an object should execute its own main loop.}
  ,status={Implemented language mechanism. Implemented library component.}
  ,example={A logging service may be implemented as an active object. Clients call \lstinline!log ("something")! on the proxy which forwards the message to the active object.}
  ,knownapps={The Java Timer class is implemented as an active object. SCOOP separate calls correspond to feature invocation on an active object.}
  ,relation={The Future pattern \patternref{FUT} is usually used for active object functions that return a result.}
  ,references={\cite[p. 369]{book:posa2}, \cite[p. 367]{book:cpj}}
]

\pattern [ name={Thread-local storage}
  ,label={TLS}
  ,category={Program structuring}
  ,intent={Provide private heap data for each thread.}
  ,applicability={When multiple threads run the same code, but each one needs a different set of data, or when the synchronization overhead for shared heap objects is undesirable.}
  ,status={Implemented language mechanism}
  ,example={Store the last exception raised in the current thread.}
 ,knownapps={Java and C\# both have a class \lstinline!ThreadLocal<T>!.}
 ,relation={ - }
 ,references={\cite[p. 475]{book:posa2}, \cite[p. 45]{book:java-concurrency}, \cite[p. 105 ]{book:cpj}, \cite[p. 53]{book:ppl}}
 ,comment={Native support in SCOOP: Use \lstinline!once("THREAD")! and a non-separate return type.}
]

\pattern [name={Publish / Subscribe}
  ,label={P/S}
  ,category={Program structuring}
  ,intent={Provide a hook to subscribe to events. In the concurrent context there's often an intermediate broker which receives events from a publisher and forwards them to all subscribers.}
  ,applicability={When the publisher doesn't need to know the subscribers, and vice versa with the broker solution.}
  ,status={Implemented library component}
  ,example={A GUI button has an event ``clicked''. The application logic can subscribe to it with a handler function.}
  ,knownapps={Event driven programming, GUI frameworks like Java Swing or EiffelVision.}
  ,relation={Similar to the Observer pattern by Gamma et al.\cite[p. 293]{book:design-patterns}, but events may come with arguments. The Eiffel agent mechanism may be used for Publish / Subscribe.}
 ,references={ - }
]

\pattern [name={Transactions}
  ,label={TRA}
  ,category={Program structuring}
  ,intent={Avoid a deadlock by reserving a set of objects one at a time. Abort if an object is already reserved by another thread.}
  ,applicability={When multiple operations need to be locked and no proper locking order can be established.}
  ,status={Possible library component}
  ,example={A banking application where multiple threads apply various operations on a set of bank accounts.}
  ,knownapps={Two-phase locking in database systems.}
  ,relation={ - }
 ,references={\cite[p. 249]{book:cpj}}
]

\subsection{SCOOP patterns}

\pattern [ name={Import}
  ,label={IMP}
  ,category={Language limitation}
  ,intent={Copy an object structure from a separate processor to the local processor.}
  ,applicability={When it's cheaper to clone the object instead of placing it on its own processor.}
  ,status={Implemented library component; future language mechanism}
  ,example={Copy the HTTP request string from the network socket listener to a request handler, such that the listener can continue.}
  ,knownapps={The library developed in this thesis makes heavy use of this pattern.}
  ,relation={ - }
 ,references={\cite[p. 106]{Nienaltowski07}}
]

\pattern [ name={Asynchronous Self-Call}
  ,label={ASC}
  ,category={Program structuring}
  ,intent={Execute the body of a main loop and then ask another processor to call back the loop body.}
  ,applicability={When a processor is running its own code, but others need to access data on it from time to time.}
  ,status={Implemented library component}
  ,example={A network socket listener that may be stopped by another processor.}
  ,knownapps={The Timer: Periodic \patternref{TP} implementation and the echo server example (see Appendix \ref{sec:echo-server}) use asynchronous self-calls.}
  ,relation={Similar to the Active Object pattern \patternref{AO}, but the Asynchronous Self-Call pattern lets other processors manipulate its data directly.}
  ,references={\cite[p. 217]{Nienaltowski07}}
]

\pattern [ name={Separate Proxy}
  ,label={SP}
  ,category={Program structuring}
  ,intent={Simplify access to a separate object by providing a processor-local proxy.}
  ,applicability={When a class is reusable (i.e. library code) and usually placed on a separate processor.}
  ,status={Guideline}
  ,example={A shared queue which gets accessed by several threads. Each thread creates a processor-local proxy to avoid having to deal with a separate reference.}
  ,knownapps={Most classes in the library have a Separate Proxy.}
  ,relation={The Separate Proxy is a special version of the proxy pattern described by Gamma et al. \cite[p. 207]{book:design-patterns}.}
  ,references={ - }
]

\pattern [name={Full Asynchrony}
  ,label={FA}
  ,category={Language limitation}
  ,intent={Perform an operation completely asynchronously.}
  ,applicability={When an operation can be run in parallel and there's no need to wait for a result.}
  ,status={Future language mechanism}
  ,example={A logger service where clients just want to send a log message without having to wait.}
  ,knownapps={A workaround is described in \cite[p. 215]{Nienaltowski07}, but it is currently broken in SCOOP.}
  ,relation={ - }
  ,references={\cite[p. 215]{Nienaltowski07}}
  , comment={Will be supported natively in the new runtime developed by Scott West \cite{thesis:scottwest}.}
]

\pattern [name={Universal Call}
  ,label={UC}
  ,category={Language limitation}
  ,intent={Provide a universal enclosing routine to perform a single call on a separate object.}
  ,applicability={When it doesn't matter if separate calls are interleaved with calls from other processors.}
  ,status={Designed language mechanism}
  ,example={A shared queue where producers only insert items.}
  ,knownapps={An implementation is described in \cite[p. 213]{Nienaltowski07}, but it is currently broken in SCOOP.}
  ,relation={The Separate Proxy \patternref{SP} is a workaround for the missing universal call.}
  ,references={\cite[p. 213]{Nienaltowski07}}
  ,comment={The new language mechanism will probably be a statement like:\newline \lstinline!separate a as l_a then l_a.do_something end!}
]

\subsection{Synchronization primitives}


\syncpattern [name={Atomic Operations}
  ,category={Synchronization primitive}
  ,intent={Avoid the use of locks by using hardware-supported atomic operations.}
  ,status={not covered}
  ,example={A lock-free queue using CompareAndSwap.}
  ,knownapps={Low-level primitive which is used to implement lock-free data structures or other synchronization primitives.}
  ,references={\cite[p. 319]{book:java-concurrency}, \cite[p. 140]{book:cpj}}
]
  
\syncpattern [name={Locks}
  ,category={Synchronization primitive}
  ,intent={An object where only one thread at a time succeeds in calling \lstinline!lock!, and others have to wait.}
  ,status={Possible library component}
  ,example={Provide exclusive access on a certain section of code.}
  ,knownapps={Low-level primitive which is often used to implement other synchronization primitives.}
  ,references={\cite[p. 277]{book:java-concurrency}, \cite[p. 148]{book:cpj}}
]

\syncpattern [name={Try Lock}
  ,category={Synchronization primitive}
  ,intent={Try to acquire a lock with the option to back off after a certain amount of time.}
  ,status={Possible library component}
  ,example={Database transactions may get aborted due to a timeout if they can't lock a resource after a certain amount of time.}
  ,knownapps={Applications with real-time requirements.}
  ,references={\cite[p. 277]{book:java-concurrency}, \cite[p. 148]{book:cpj}}
]

\syncpattern [name={Read / Write lock}
  ,category={Synchronization primitive}
  ,intent={Allow multiple concurrent readers but provide exclusive access to a writer.}
  ,status={Language limitation}
  ,example={An array with frequent concurrent reads can make use of a read / write lock.}
  ,knownapps={Shared, read-mostly data structures.}
  ,references={\cite[p. 286]{book:java-concurrency}, \cite[p. 157]{book:cpj}}
]

\syncpattern [name={Semaphore}
  ,category={Synchronization primitive}
  ,intent={Make sure that only a certain amount of threads can execute a section of code.}
  ,status={Possible library component}
  ,example={The dining philosophers pattern, where at most (N-1) philosophers can eat.}
  ,knownapps={Can be used to implement other synchronization primitives.}
  ,references={\cite[p. 98]{book:java-concurrency}, \cite[p. 220]{book:cpj}}
]

\syncpattern [ name={Single Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to exactly one shared object or resource.}
  ,status={Implemented language mechanism}
  ,example={A counter variable that shold only be incremented by one thread at a time to avoid lost updates.}
  ,knownapps={The Java \lstinline!synchronized! and C\# \lstinline!lock! statements implement single exclusive access for sections of code.}
  ,references={\cite[p. 25]{book:java-concurrency}, \cite[p. 76]{book:cpj}}
  ]

\syncpattern [ name={Multiple Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to several shared objects or resources.}
  ,status={Implemented language mechanism}
  ,example={A money transfer between two bank accounts.}
  ,knownapps={Databases can provide exclusive access over all data items previously used in the same transaction.}
%   ,comment={It is possible to use nested single exclusive access to provide multiple exclusive access, but special care has to be taken with deadlocks.}
  ,references={ - }
  ]

\syncpattern [name={Barrier}
  ,category={Synchronization primitive}
  ,intent={Provide a synchronization point where several threads have to meet before continuing.}
  ,status={Possible library component}
  ,example={If the computation of a matrix multiplication is divided among threads, a barrier can be used to make sure that all threads finish before the result is used.}
  ,knownapps={Parallel matrix operations, parallel loop processing.}
  ,references={\cite[p. 99]{book:java-concurrency}, \cite[p. 362]{book:cpj}}
]

\syncpattern [name={Monitor}
  ,category={Synchronization primitive}
  ,intent={Ensure that only one thread has access to an object. The thread may also wait for a condition to become true.}
  ,status={Implemented language mechanism}
  ,example={A shared buffer with conditions \lstinline!is_empty! and \lstinline!is_full!.}
  ,knownapps={Java with a combination of \lstinline!synchronized!, \lstinline!wait()! and \lstinline!notifiyAll()!}
  ,comment={The monitor pattern is a combination of single exclusive access and condition variables.}
  ,references={\cite[p. 399]{book:posa2}, \cite[p. 184]{book:cpj}}
]

\syncpattern [name={Condition Variables}
  ,category={Synchronization primitive}
  ,intent={Wait for a certain condition to become true.}
  ,status={Implemented language feature, possible library component}
  ,example={When a buffer is empty, consumers can wait on the \lstinline!is_not_empty! conditon variable. Producers will send a signal on this variable when a new item is available.}
  ,knownapps={Preconditions in SCOOP are effectively condition variables due to their wait semantics.}
  ,references={\cite[p. 298 and 306]{book:java-concurrency}}
]

\syncpattern [name={Synchronous Message Passing}
  ,category={Synchronization primitive}
  ,intent={Send a message from a sender to a receiver synchronously, where both have to wait until the operation has completed.}
  ,status={Possible library component}
  ,example={Make a flight reservation with the implicit guarantee that the booking system has received the message.}
  ,knownapps={Main synchronizaton mechanism in message passing systems.}
  ,references={\cite[p. 369]{book:cpj}}
]
