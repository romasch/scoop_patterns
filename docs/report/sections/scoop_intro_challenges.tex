 
\section {The SCOOP model}
\label {sec:scoop-model}
% Introduction, differences to Java etc... (short)

SCOOP is an extension to the Eiffel programming language that aims to make concurrent programming easier.
The basic idea is that every object can be accessed by exactly one computational unit only.
This unit is called processor or handler of an object.

The keyword \lstinline!separate! is used to indicate that an object may be handled by a different processor than the handler for \lstinline!Current!.
Calls to a separate object (``separate calls'') then correspond to sending a message to the foreign processor.
There are two types of separate calls: synchronous and asynchronous.
If the called feature returns a result the call is synchronous, which means that the current processor has to wait for the foreign processor to finish its task.
An asynchonous call happens when the feature is a command, i.e. not returning any result.
In that case both processors can proceed concurrently.

A separate call is only allowed if its target is ``controlled''.
Controlling an object means that the user has exclusive access to that object.
In that sense controlling corresponds a bit to locking in other languages.
In order to control an object it has to appear as a formal argument in the enclosing routine.

SCOOP guarantees that all messages sent by the current processor are handled in the correct order by the foreign processor.
The exclusive access and order guarantee ensure that a controlled separate object behaves just like an object in a sequential program.
This is the reason why the SCOOP model is so simple: 
It allows reasoning about a feature body without the need to consider all possible interleavings of two parallel executions.

A new processor is created by calling a creation instruction on a variable which is declared as separate.
The new object is then handled by the new processor.

Preconditions in SCOOP have a special role.
In a concurrent setting there's often the problem that a correctness condition may change due to unfortunate interleaving, 
e.g. between checking that a buffer is not empty and then removing an item, the buffer actually becomes empty due to interference from another thread.
Therefore SCOOP turns preconditions into wait conditions if they reference a separate object.

There are many advantages to the SCOOP model, such as easier reasoning and absence of data races, but it also has some shortcomings.
It is for example often necessary to write lots of little helper functions that just take a separate object and perform a single call on it,
because SCOOP enforces taht every target of a separate call needs to be controlled.

SCOOP also has performance problems because it transforms every separate call into a message to another processor.
This is rather expensve, especially for small functions like array access.

Furthermore, a processor is currently implemented as an operating system thread and creating them is a costly operation that involves context switches.
The SCOOP model however encourages the creation of many processors which is not ideal for performance reasons.

\section{Challenges in SCOOP}
\label{sec:scoop-challenges}
% This section describes recurring challenges in SCOOP and how to solve them...

\subsection{Object migration}
\label{sec:object-migration}

Passing data from one processor to another is often necessary when programming in SCOOP.
The most obvious example is the Producer / Consumer pattern \patternref{P/C}, but it also applies to other situations like providing some arguments to an asynchronous command.

There are two categories of objects which can be passed as arguments: expanded and reference types.
Passing expanded objects, which also includes basic types such as \lstinline!INTEGER!, is not a problem in SCOOP due to their copy-semantics property.
However, passing a reference object from one processor to another is a bit more tricky
because bad things such as starvation or unintentional lock passing may happen if done wrong.

There are essentially three ways to safely move reference objects from a sender to a receiver processor.
The first and easiest solution is to create the data on its own, separate processor: 
\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={Migrate objects on a separate processor.}]
class SENDER feature
  send (a_receiver: separate RECEIVER)
      -- Invoke an asynchronous operation with
      -- an argument on `a_receiver'.
    local
      args: separate ANY
    do
      create args
      a_receiver.do_something (args)
    end
end

class RECEIVER feature 
  do_something (args: separate ANY)
      -- Perform some operation with `args'.
    do
      print (args)
    end
end
\end{lstlisting}
This approach is conceptually easy but not very efficient, especially when the argument object is small.
We'll call this solution the Data Processor approach.

Another solution is to create the object on the same handler as the sender object:
\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={Migrate objects with lock passing.}]
class SENDER feature
  send (a_receiver: separate RECEIVER)
      -- Invoke an asynchronous operation with
      -- an argument on `a_receiver'.
    local
      args: ANY
    do
      create args
      a_receiver.do_something (args)
    end
end

class RECEIVER feature 
  do_something (args: separate ANY)
      -- Perform some operation with `args'.
    do
      print (args)
    end
end
\end{lstlisting}
This solution (the Lock Passing approach) looks almost like the first one.
The only change is a missing separate keyword.
The semantics however are radically different:

\begin{itemize}
 \item The feature \lstinline!do_something! is executed synchronously due to the lock passing mechanism \cite[p. 152]{Nienaltowski07}\cite{web:scoop}.
 This means that the sender class needs to wait for it to finish.
 \item \lstinline!RECEIVER! can't lock the argument object any more after \lstinline!do_something! finishes.
 In particular this means that the receiver class should not store the argument in one of its attributes, because any attempt to access it later will likely result in starvation.
 The reason for this is that the handler of \lstinline!SENDER! will continue its execution, and as long as there's still work to do no other processor can access objects on it .
 \item Compared to the first approach no new processor is created.
\end{itemize}

The last method makes use of a special SCOOP mechanism called \lstinline!import!:
\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={Migrate objects with import.}]
class SENDER feature
  send (a_receiver: separate RECEIVER)
      -- Invoke an asynchronous operation with
      -- an argument on `a_receiver'.
    local
      args: ANY
    do
      create args
      a_receiver.receive_args (args)
      a_receiver.do_something
    end
end

class RECEIVER feature
  
  received: ANY
  
  receive_args (args: separate ANY)
      -- Receive some arguments
    do
      received := import (args)
    end

  do_something
      -- Perform some operation.
    do
      print (received)
    end
end
\end{lstlisting}
The \lstinline!import! feature copies its argument along with all non-separate references to the local processor.
It is somewhat similar to \lstinline!{ANY}.deep_copy!, except that it doesn't follow separate references.

The import solution has several advantages.
There is no need for a new processor, and the receiver can keep the data and do the operation asynchronously.
The drawback is that the data needs to be copied.
However, for small data items this is actually faster than creating a new thread.

Note that \lstinline!receive_args! is executed synchronously just as in the Lock Passing approach.
To execute \lstinline!do_something! asynchronously it has therefore been divided into an execution and argument receiving part.

The feature \lstinline!import! was first described in \cite[p. 106]{Nienaltowski07}, but unfortunately it is not implemented in current SCOOP.
It is possible however to implement it manually with some user support.

\subsection{Processor communication}
\label{sec:processor-communication}
% Problem that two concurrent, active processors can't communicate. Example downloader task.
% Solution: a third, passive processor with a shared data structure.

It is often the case that two threads need to communicate with each other.
An example would be a user interface with a background download task.
The user interface needs to be able to cancel the download, and the download task has to inform the GUI when it is finished.

In SCOOP this is not easily done.
Both processors are performing a long-running execution, which doesn't allow other processors to do separate calls on them.
Specifically, the GUI processor is in an infinite loop to receive input and repaint the window, whereas the download task is busy receiving chunks of data.
Cancellation will not work in this case because the user interface processor will have to wait for the download processor to finish until it can actually access the download task to call \lstinline!cancel!, 
which kind of defeats the purpose of the cancellation button.
Worse yet, the user interface will freeze until the GUI processor finally gets the lock.

The solution to this kind of problem is to introduce a third processor which is ``passive'', meaning that it doesn't have a task to perform and only waits for incoming requests.
This new processor is known to the other two, ``active'' processors and handles an object which can be used for communication.
In our example the ``passive'' processor has an object with an \lstinline!is_cancelled! and \lstinline!is_finished! boolean flag.
The ``active'' processors then regularly need to check the status of these flags.

The solution to the task cancellation problem comes from a previous paper by the Software Engineering group \cite{paper:task-cancellation}.

\subsection{Processor termination}
\label{sec:processor-termination}
% Problem: how to stop consumer waiting on empty buffer.
% Solution: Query is_stopped in shared buffer.

When an application terminates it is necessary to stop any running thread.
Sometimes this can be done with processor communication as seen in Section \ref{sec:processor-communication}.
A problem arises however when a processor is stuck in a wait condition.

One example of this could be a producer / consumer situation where a consumer is waiting for the buffer to become non-empty.
If the producers have terminated already, the consumer never gets the chance to break out of its wait condition and therefore cannot terminate successfully.

The solution is to add a query \lstinline!is_stop_requested! in the shared buffer and to adapt the wait condition to include the stop request:

\begin{lstlisting}[language=OOSC2Eiffel, captionpos=b, caption={Breaking out of a wait condition.}]
class
  CONSUMER

feature -- Status report

  buffer: separate BUFFER
  
  last_item: INTEGER
  
  is_stopped: BOOLEAN
  
feature -- Basic operations
  
   start
      -- Start the main loop
    do
      from
        fetch (buffer)
      until 
        is_stopped
      loop
          -- Do something, e.g.
        print (last_item)

        fetch (buffer)
      end
    end
  
feature -- Implementation

  fetch (buf: separate BUFFER)
      -- Get the next item from `buf'.
    require
      not buf.is_empty or buf.is_stop_requested
    do
      if buf.is_stop_requested then
        is_stopped := True
      else
        last_item := buf.item
        buf.remove
      end
    end
end
\end{lstlisting}

This allows a consumer to leave the wait condition even when the buffer is empty.
The drawback of this approach is that it clutters the application code with some additional if-else constructs, 
but it is often possible to hide them in a \lstinline!fetch! function, as shown in our example.
