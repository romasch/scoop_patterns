
\subsection{Data centered patterns}

\pattern [name={Producer / Consumer}
  ,category={Program structuring}
  ,intent={Provide a synchronized shared buffer. Producer threads put items into the buffer, and consumers remove items.}
  ,applicability={When participants should not know each other. Also applicable if there's no one-to-one relation between producers and consumers or when buffering is desired.}
  ,status={Implemented library component}
  ,example={A logger service, where many producers submit log messages to a buffer and a single consumer writes them to a file.}
  ,knownapps={Very widely used. E.g. logging, input processing, buffering web server requests.}
  ,relation={The worker pool uses this pattern to pass along tasks. Pipeline and Dataflow networks are several chained Producer / Consumer patterns.}
%  ,references={}
]

\pattern [name={Pipeline}
  ,category={Program structuring}
  ,intent={Process a stream of data in several independent stages.}
  ,applicability={When the input consist of a stream of data where several processing steps need to be performed.}
  ,status={Possible library component}
  ,example={An emailing system that applies a spam filter, database logging, and a virus scan to each incoming email.}
  ,knownapps={Messaging systems, multimedia streaming (receive - decode - display)}
  ,relation={The producer / consumer pattern is used between two stages. Pipeline is a special form of Dataflow Network.}
%  ,references={}
]

\pattern [name={Dataflow Network}
  ,category={Program structuring}
  ,intent={Process a stream of data in independent stages, with the option to branch and merge streams.}
  ,applicability={When the input consists of a stream of data which allows for parallel processing.}
  ,status={Possible library component}
  ,example={A video player application that internally has a file decoder stage, which splits the input in an audio and video part, which then gets further processed.}
  ,knownapps={The borealis engine \todoref.}
  ,relation={The pattern is related to Pipeline. However in Dataflow Network the data can be split by one stage and forwarded to two different stages and maybe merged again later.}
%  ,references={}
]

\pattern [name={Exchanger}
%   ,category={}
  ,intent={Exchange two objects between two threads atomically.}
  ,applicability={When the synchronization point and the atomicity is required.}
  ,status={Possible library component.}
  ,example={A logger with two buffers: One is used by clients to submit messages, the other is used by the logger to write messages. When the latter is empty and the former is full, an exchange happens.}
  ,knownapps={Hardly ever used.}
  ,relation={Similar to Handshake, except that data passes in both directions.}
%  ,references={}
]

\subsection{Task centered patterns}


\pattern [name={Worker Pool}
  ,category={Performance}
  ,intent={Avoid expensive thread cration by providing a set of threads that can execute arbitrary operations.}
  ,applicability={When there are a lot of small tasks that may be executed in parallel.}
  ,status={Implemented library component}
  ,example={A set of HTTP request handlers in a web server.}
  ,knownapps={Web servers.}
  ,relation={Producer / Consumer is used to pass along task objects. Worker Pool is usually an implementation of Executor framework.}
%  ,references={}
]

\pattern [ name={Future}
  ,category={Program structuring, Performance}
  ,intent={Run a task asynchronously, and fetch the result later.}
  ,applicability={When a computation may be run in parallel, but creating an extra thread is too expensive.}
  ,status={Implemented library component}
  ,example={A web browser which starts downloads tasks for image files in parallel to parsing and rendering the HTML file.}
  ,knownapps={In UI programming for long-running background tasks, or parallelization of certain numerical computations.}
  ,relation={Futures may be backed by worker pools that execute them.}
%  ,references={}
  ,comment={The wait-by-necessity semantics of SCOOP also corresponds to the Future pattern.}
]

\pattern [name={Executor framework}
  ,category={Program structuring}
  ,intent={Split task submission from task execution.}
  ,applicability={When the task execution strategy should be flexible, e.g. using a worker pool or creating a new thread per task.}
  ,status={Implemented library component.}
  ,example={The Java Executor interface, where descendants can decide wether a submitted Runnable object is executed in the current thread, in a new thread, or in a worker pool.}
  ,knownapps={Jave Executor interface, Microsoft TPL \todoref}
  ,relation={The worker pool is an implementation of an executor service.}
%  ,references={}
]

\pattern [name={Timer: Periodic}
  ,category={Program structuring}
  ,intent={Apply an operation repeatedly in regular intervals.}
  ,applicability={When an operation, which can be run in parallel to the applications main execution, needs to be applied repeadedly.}
  ,status={Implemented library component}
  ,example={An emailing application that checks for new messages every five seconds.}
  ,knownapps={Message polling, flushing buffers, repeated log write, heartbeat messages, cron jobs.}
  ,relation={Similar to Active Object, but it schedules just one operation repeatedly.}
%  ,references={}
]

\pattern [ name={Timer: Invoke later}
  ,category={Program structuring}
  ,intent={Invoke a certain operation at a later point in time.}
  ,applicability={When an operation can be run in parallel, at a later point in time.}
  ,status={Implemented library component}
  ,example={Send an email after a delay of one minute, in which the user can still press ``cancel''\todo{do we actually support cancellation?}}
  ,knownapps={``Grace periods'' to cancel an action, robotics control, alarm clocks.}
  ,relation={ - }
%  ,references={}
]

\subsection{I/O patterns}

\pattern [name={Half-Sync / Half-Async}
  ,category={Program structuring}
  ,intent={Simplify asynchronous event handling. A thread or an interrupt handler listens on an event source and puts incoming messages in a synchronized queue. Worker threads then retrieve and handle requests.}
  ,applicability={When the application must react to several event sources at the same time.}
  ,status={Uncovered}
  ,example={The networking stack of most UNIX system is implemented like this. A network socket is the ``queue'', which gets filled by interrupt handlers. An application thread then takes care of handling the data.}
  ,knownapps={Network sockets, web servers.}
  ,relation={ - }
  ,references={\cite[p. 423]{book:posa2}}
]

\pattern [name={Leader / Followers}
  ,category={Performance, Program structuring}
  ,intent={Listen on several I/O sockets using a thread pool. A leader thread receives a request, promotes the next leader, and then handles the request.}
  ,applicability={When there are hundreds of I/O sockets.}
  ,status={Uncovered}
  ,example={A web server for a high volume website serving thousands of connections at the same time.}
  ,knownapps={Online Transaction Processing (OLTP) applications.}
  ,relation{Compared to Half-Sync / Half-Async it avoids the synchronization overhead of the shared queue.}
 ,references={\cite[p. 447]{book:posa2}, \cite{paper:schmidt00leader}}
]

\pattern [name={Disruptor}
  ,category={Performance, Program structuring}
  ,intent={Provide a high-performance ring buffer with a single producer and multiple readers, each assigned to a thread. Readers can change buffer entries and have dependencies to other readers.}
  ,applicability={When very high throughput in an I/O application is required.}
  ,status={Uncovered}
  ,example={An OLTP system where the producer listens on a socket for new requests. Then there's a reader for each of the following tasks: logging, unmarshalling, handling of request.}
  ,knownapps={LMAX Exchange uses this pattern for their trading platform.}
  ,relation={Similar to Half-Synch/Half-Asynch, but with more functionality and buffer entries may be accessed by several threads.}
 ,references={\cite{thompson2011disruptor}}
]

\subsection{Miscellaneous patterns}

\pattern [name={Active Object \todo{Examples etc...}}
  ,category={Program structuring}
  ,intent={Pair an object with its own thread. Clients access the active object through a proxy object, which transforms feature calls to asynchronous messages. 
  The object runs a main loop where it schedules requests from other processors and runs its own code.}
  ,applicability={When access to a shared resource can be guarded and scheduled by an object, or when an object may run its own main loop.}
  ,status={Implemented language mechanism. Implemented library component.}
  ,example={A logging service may be implemented as an active object. Clients call \lstinline!log (``something'')! on the proxy, which forwards the message to the active object.}
  ,knownapps={The Java Timer class is implemented as an active object. SCOOP separate calls correspond to feature invocation on an active object.}
  ,relation={The Future pattern is usuallz used for active object features that return a result.}
  ,references={\cite[p. 369]{book:posa2}}
]

\pattern [ name={Thread-local storage}
  ,category={Program structuring}
  ,intent={Provide private heap data for each thread.}
  ,applicability={When multiple threads run the same code, but each needs a different set of data, or if synchronization overhead for heap objects is undesirable.}
  ,status={Implemented language mechanism.}
  ,example={Store the last exception raised in the current thread.}
 ,knownapps={Java and C\# both have a class ThreadLocal<T>.}
 ,relation={ - }
 ,references={\cite[p. 475]{book:posa2}}
 ,comment={Native support in SCOOP: use \lstinline!once(``THREAD'')! and non-separate return type.}
]

\pattern [name={Publish / Subscribe}
  ,category={Program structuring}
  ,intent={Provide a hook to subscribe to events. In the concurrent context there's often an intermediate broker which receives events from a publisher and forwards them to all subscribers.}
  ,applicability={When the publisher doesn't need to know the subscribers, and vice versa in the broker solution.}
  ,status={Possible library component}
  ,example={A GUI button has an event ``clicked'', where the application logic can provide a handler.}
  ,knownapps={Event driven programming, GUI frameworks like Java Swing or EiffelVision.}
%   ,relation={}
%  ,references={}
]

\pattern [name={Transactions}
  ,category={Program structuring}
  ,intent={Avoid a deadlock by ``reserving'' a set of objects one at a time. Abort if an object is already reserved by another thread.}
  ,applicability={When multiple operations need to be locked and no locking order can be established.}
  ,status={Possible library component}
  ,example={A banking application where two accounts need to be locked for a transfer.}
  ,knownapps={Two-phase locking in database systems.}
  ,relation={ - }
%  ,references={}
]



\subsection{SCOOP patterns}

\pattern [ name={Import}
  ,category={Language limitation}
  ,intent={Copy an object structure from a separate processor to the local processor.}
  ,applicability={When it's cheaper to copy the object instead of creating it on a new processor.}
  ,status={Implemented library component; future language mechanism}
  ,example={Copy the HTTP request string from the network socket listener to a request handler, such that the listener can continue.}
  ,knownapps={The library makes heavy use of this pattern.}
  ,relation={ - }
%  ,references={}
]

\pattern [ name={Self Asynch}
  ,category={Program structuring}
  ,intent={Execute the body of a main loop, and then ask a separate processor to call back the loop body.}
  ,applicability={When a processor is running its own code, but others need to access data on it from time to time.}
  ,status={Implemented library component}
  ,example={A network socket listener that may be stopped by another process.}
  ,knownapps={The timer pattern and the echo server use self asynch.}
  ,relation={Similar to the Active Object pattern, but Self Asynch lets other processors manipulate its data directly.}
%  ,references={}
]

\pattern [ name={Separate Proxy}
  ,category={Program structuring}
  ,intent={Simplify access to a separate object by providing a processor-local proxy.}
  ,applicability={When a class is reusable (library code) and usually created on a separate processor.}
  ,status={Guideline}
  ,example={A shared queue which gets accessed by several thread. Each thread creates a processor-local proxy to avoid having to deal with a separate reference.}
  ,knownapps={Most classes in the library ship with a separate proxy.}
  ,relation={The separate proxy is a special version of the more general GoF \todo{ref} proxy pattern.}
%  ,references={}
]

\pattern [name={Full Asynchrony}
  ,category={Language limitation}
  ,intent={Perform an operation completely asynchronously.}
  ,applicability={When an operation can be run in parallel and there's no need to wait for a result.}
  ,status={Future language mechanism}
  ,example={A logger service where clients just want to send a log message without having to wait.}
  ,knownapps={A workaround exists in \todoref, but it's broken with current SCOOP.}
  ,relation={ - }
%  ,references={}
  , comment={Will be natively supported with the new runtime by Scott West.}
]

\pattern [name={Universal Call}
  ,category={Language limitation}
  ,intent={Provide a universal enclosing routine to perform a single separate call.}
  ,applicability={When calls to a separate object may be interleaved with calls from other processors.}
  ,status={Designed language mechanism}
  ,example={A separate queue where producers just insert new items.}
  ,knownapps={An implementation exists in \todoref, but it's broken with current SCOOP.}
  ,relation={The separate proxy is a workaround for the missing universal call (especially when no compound actions are defined).}
%  ,references={}
  , comment={The new language mechanism will probably be a statement like \lstinline!separate a as l_a then l_a.do_something end!.}
]


\pattern [name={EiffelVision support}
%   ,category={}
%   ,intent={}
%   ,applicability={}
%   ,status={}
%   ,example={}
%   ,knownapps={}
%   ,relation={}
%  ,references={}
]

\subsection{Synchronization primitives}


\syncpattern [name={Atomic Operations}
  ,category={Synchronization primitive}
  ,intent={Avoid the use of locks by using hardware-supported atomic operations.}
%   ,applicability={Shared memory systems}
  ,status={unsolved}
  ,example={A lock-free queue with the help of CompareAndSwap.}
  ,knownapps={Low-level primitive which is used to implement lock-free data structures or other synchronization primitives.}
%   ,relation={}
]
  
\syncpattern [name={Locks}
  ,category={Synchronization primitive}
  ,intent={An object where only one thread at a time succeeds in calling \lstinline!lock!, and others have to wait.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={Provide exclusive access on a certain section of code.}
  ,knownapps={Low-level primitive which is often used to implement other synchronization primitives.}
%   ,relation={}
]

\syncpattern [name={TryLock}
  ,category={Synchronization primitive}
  ,intent={Try to acquire a lock, with the option to back off after a certain amount of time.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={Database transactions may get aborted due to a timeout if they can't lock a resource after a certain amount of time.}
  ,knownapps={Applications with real-time requirements.}
%   ,relation={}
]

\syncpattern [name={Read / Write lock}
  ,category={Synchronization primitive}
  ,intent={Allow multiple concurrent readers, but provide exclusive access to a single writer.}
%   ,applicability={}
  ,status={Language limitation}
  ,example={An array with frequent concurrent reads can make use of a read / write lock.}
  ,knownapps={Shared, read-mostly data structures.}
%   ,relation={}
]

\syncpattern [name={Semaphore}
  ,category={Synchronization primitive}
  ,intent={Make sure that only a certain amount of threads can execute a certain code section.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={The dining philosophers pattern, where at most (N-1) philosophers can eat.}
  ,knownapps={Can be used to implement other synchronization primitives.}
%   ,relation={Similar to a barrier.}
]

\syncpattern [ name={Single Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to exactly one shared object or resource.}
%  ,applicability={Shared memory systems}
  ,status={Implemented language mechanism}
  ,example={A counter variable that shold only be incremented by one thread at a time to avoid lost updates.}
  ,knownapps={The Java ``synchronized'' block implements single exclusive access, as well as C\# ``lock''.}
%   ,relation={Usually implemented with some kind of locking mechanism.}
  ]

\syncpattern [ name={Multiple Exclusive Access}
  ,category={Synchronization Primitive}
  ,intent={Make sure that at most one thread has access to several shared objects or resources.}
%  ,applicability={Shared memory systems}
  ,status={Implemented language mechanism}
  ,example={A money transfer between two bank accounts.}
  ,knownapps={Databases can provide exclusive access over all data previously used in the same transaction.}
%   ,relation={It is possible to use nested single exclusive access to provide multiple exclusive access, but special care has to be taken with deadlocks.}
  ]

\syncpattern [name={Barrier}
  ,category={Synchronization primitive}
  ,intent={Provide a synchronization point where several threads have to meet before continuing.}
%   ,applicability={}
  ,status={Possible library component}
  ,example={If the computation of a matrix multiplication is split among threads, the barrier can be used to make sure that all threads finish before the result can be used}
  ,knownapps={Parallel matrix operations, parallel loop processing.}
%   ,relation={}
]

\syncpattern [name={Monitor}
  ,category={Synchronization primitive}
  ,intent={Ensure that only one thread has access to an object. The thread may also wait on a condition to become true or false.}
%   ,applicability={}
  ,status={Implemented language mechanism}
  ,example={A shared buffer with conditions \lstinline!is_empty! and \lstinline!is_full!.}
  ,knownapps={Java with a combination of \lstinline!synchronized!, \lstinline!wait ()! and \lstinline!notifiyAll()!}
  ,comment={The monitor pattern is a combination of single exclusive access and condition variables.}
  ,references={\cite[p. 399]{book:posa2}}
]

\syncpattern [name={Condition Variables}
  ,category={Synchronization primitive}
  ,intent={Wait for a certain condition to become true.}
%   ,applicability={}
  ,status={Implemented language feature, possible library component}
  ,example={When a buffer is empty, a consumer can wait on the is\_not\_empty conditon variable. Producers will signal on this variable when a new item is available.}
  ,knownapps={Preconditions in SCOOP are effectively condition variables, due to their wait semantics.}
%   ,relation={}
]

\syncpattern [name={Synchronous message passing}
  ,category={Synchronization primitive}
  ,intent={Send a message from sender to receiver synchronously, where both must wait until the operation has completed.}
%  ,applicability={When the sender needs a delievery guarantee.}
  ,status={Possible library component}
  ,example={Make a flight reservation, with the implicit guarantee that the booking system has received the message.}
  ,knownapps={Main synchronizaton mechanism in message passing systems.}
%   ,relation={}
]
